<text font="0" height="19" left="221" textpieces="0" top="175" width="481">Socioscope: Spatio-Temporal Signal Recovery</text>
<text font="0" height="19" left="365" textpieces="0" top="202" width="194">from Social Media</text>
<text font="1" height="13" left="219" textpieces="1" top="259" width="485">Jun-Ming Xu&#8224;, Aniruddha Bhargava&#8727;, Robert Nowak&#8727;, and Xiaojin Zhu&#8224;&#8727;</text>
<text font="3" height="8" left="355" textpieces="0" top="288" width="212">&#8224;Department of Computer Sciences</text>
<text font="3" height="8" left="299" textpieces="0" top="304" width="324">&#8727;Department of Electrical and Computer Engineering</text>
<text font="4" height="12" left="282" textpieces="0" top="324" width="359">University of Wisconsin-Madison, Madison WI 53706, USA</text>
<text font="4" height="11" left="260" textpieces="0" top="341" width="402">xujm@cs.wisc.edu, aniruddha@wisc.edu, nowak@ece.wisc.edu,</text>
<text font="4" height="11" left="391" textpieces="0" top="358" width="141">jerryzhu@cs.wisc.edu</text>
<text font="4" height="12" left="245" textpieces="0" top="413" width="434">Abstract. Many real-world phenomena can be represented by a spatio-</text>
<text font="4" height="12" left="245" textpieces="0" top="429" width="434">temporal signal: where, when, and how much. Social media is a tantaliz-</text>
<text font="4" height="12" left="245" textpieces="0" top="446" width="434">ing data source for those who wish to monitor such signals. Unlike most</text>
<text font="4" height="12" left="245" textpieces="0" top="462" width="434">prior work, we assume that the target phenomenon is known and we are</text>
<text font="4" height="12" left="245" textpieces="0" top="479" width="434">given a method to count its occurrences in social media. However, count-</text>
<text font="4" height="12" left="245" textpieces="0" top="495" width="434">ing is plagued by sample bias, incomplete data, and, paradoxically, data</text>
<text font="4" height="12" left="245" textpieces="0" top="512" width="434">scarcity &#8211; issues inadequately addressed by prior work. We formulate sig-</text>
<text font="4" height="12" left="245" textpieces="0" top="528" width="434">nal recovery as a Poisson point process estimation problem. We explicitly</text>
<text font="4" height="12" left="245" textpieces="0" top="545" width="434">incorporate human population bias, time delays and spatial distortions,</text>
<text font="4" height="12" left="245" textpieces="0" top="561" width="434">and spatio-temporal regularization into the model to address the noisy</text>
<text font="4" height="12" left="245" textpieces="0" top="577" width="434">count issues. We present an e&#64259;cient optimization algorithm and discuss</text>
<text font="4" height="12" left="245" textpieces="0" top="594" width="434">its theoretical properties. We show that our model is more accurate than</text>
<text font="4" height="12" left="245" textpieces="0" top="610" width="434">commonly-used baselines. Finally, we present a case study on wildlife</text>
<text font="4" height="12" left="245" textpieces="0" top="627" width="434">roadkill monitoring, where our model produces qualitatively convincing</text>
<text font="4" height="12" left="245" textpieces="0" top="643" width="43">results.</text>
<text font="5" height="16" left="202" textpieces="1" top="689" width="141">1  Introduction</text>
<text font="1" height="13" left="202" textpieces="0" top="725" width="519">Many real-world phenomena of interest to science are spatio-temporal in nature.</text>
<text font="1" height="16" left="202" textpieces="1" top="743" width="519">They can be characterized by a real-valued intensity function f &#8712; R&#8805;0, where</text>
<text font="1" height="13" left="202" textpieces="1" top="761" width="519">the value fs,tquanti&#64257;es the prevalence of the phenomenon at location s and time</text>
<text font="1" height="13" left="202" textpieces="0" top="779" width="519">t. Examples include wildlife mortality, algal blooms, hail damage, and seismic</text>
<text font="1" height="13" left="202" textpieces="0" top="796" width="519">intensity. Direct instrumental sensing of f is often di&#64259;cult and expensive. So-</text>
<text font="1" height="13" left="202" textpieces="0" top="814" width="519">cial media o&#64256;ers a unique sensing opportunity for such spatio-temporal signals,</text>
<text font="1" height="13" left="202" textpieces="0" top="832" width="519">where users serve the role of &#8220;sensors&#8221; by posting their experiences of a target</text>
<text font="1" height="13" left="202" textpieces="0" top="850" width="519">phenomenon. For instance, social media users readily post their encounters with</text>
<text font="1" height="13" left="202" textpieces="0" top="868" width="475">dead animals: &#8220;I saw a dead crow on its back in the middle of the road.&#8221;</text>
<text font="1" height="13" left="225" textpieces="0" top="886" width="496">There are at least three challenges faced when using human social media</text>
<text font="1" height="13" left="202" textpieces="0" top="904" width="106">users as sensors:</text>
<text font="1" height="13" left="208" textpieces="0" top="932" width="512">1. Social media sources are not always reliable and consistent, due to factors</text>
<text font="1" height="13" left="228" textpieces="0" top="950" width="493">including the vagaries of language and the psychology of users. This makes</text>
<text font="1" height="13" left="228" textpieces="0" top="968" width="493">identifying topics of interest and labeling social media posts extremely chal-</text>
<text font="1" height="13" left="228" textpieces="0" top="986" width="51">lenging.</text>
<text font="4" height="12" left="202" textpieces="1" top="142" width="328">2       Xu, J., Bhargava, A., Nowak, R., and Zhu, X.</text>
<text font="1" height="13" left="208" textpieces="0" top="180" width="512">2. Social media users are not under our control. In most cases, users cannot be</text>
<text font="1" height="13" left="228" textpieces="0" top="198" width="493">directed or focused or maneuvered as we wish. The distribution of human</text>
<text font="1" height="13" left="228" textpieces="0" top="216" width="493">users (our sensors) depends on many factors unrelated to the sensing task</text>
<text font="1" height="13" left="228" textpieces="0" top="234" width="55">at hand.</text>
<text font="1" height="13" left="208" textpieces="0" top="252" width="512">3. Location and time stamps associated with social media posts may be er-</text>
<text font="1" height="13" left="228" textpieces="0" top="270" width="493">roneous or missing. Most posts do not include GPS coordinates, and self-</text>
<text font="1" height="13" left="228" textpieces="0" top="288" width="493">reported locations can be inaccurate or false. Furthermore, there can be</text>
<text font="1" height="13" left="228" textpieces="0" top="306" width="493">random delays between an event of interest and the time of the social media</text>
<text font="1" height="13" left="228" textpieces="0" top="324" width="165">post related to the event.</text>
<text font="1" height="13" left="202" textpieces="0" top="355" width="519">Most prior work in social media event analysis has focused on the &#64257;rst challenge.</text>
<text font="1" height="13" left="202" textpieces="0" top="373" width="519">Sophisticated natural language processing techniques have been used to identify</text>
<text font="1" height="13" left="202" textpieces="0" top="391" width="519">social media posts relevant to a topic of interest [21, 2, 16] and advanced machine</text>
<text font="1" height="13" left="202" textpieces="0" top="409" width="519">learning tools have been proposed to discover popular or emerging topics in social</text>
<text font="1" height="13" left="202" textpieces="0" top="427" width="440">media [1, 12, 22]. We discuss the related work in detail in Section 3.</text>
<text font="1" height="13" left="225" textpieces="0" top="445" width="496">Our work in this paper focuses on the latter two challenges. We are interested</text>
<text font="1" height="13" left="202" textpieces="0" top="463" width="519">in a speci&#64257;c topic or target phenomenon of interest that is given and &#64257;xed be-</text>
<text font="1" height="13" left="202" textpieces="0" top="481" width="519">forehand, and we assume that we are also given a (perhaps imperfect) method,</text>
<text font="1" height="13" left="202" textpieces="0" top="499" width="519">such as a trained text classi&#64257;er, to identify target posts. The &#64257;rst challenge is</text>
<text font="1" height="13" left="202" textpieces="0" top="517" width="519">relevant here, but is not the focus of our work. The main concerns of this paper</text>
<text font="1" height="13" left="202" textpieces="0" top="535" width="519">are to deal with the highly non-uniform distribution of human users (sensors),</text>
<text font="1" height="13" left="202" textpieces="0" top="553" width="519">which profoundly a&#64256;ects our capabilities for sensing natural phenomena such as</text>
<text font="1" height="13" left="202" textpieces="0" top="571" width="519">wildlife mortality, and to cope with the uncertainties in the location and time</text>
<text font="1" height="13" left="202" textpieces="0" top="589" width="519">stamps associated with related social media posts. The main contribution of the</text>
<text font="1" height="13" left="202" textpieces="0" top="607" width="519">paper is robust methodology for deriving accurate spatiotemporal maps of the</text>
<text font="1" height="13" left="202" textpieces="0" top="625" width="336">target phenomenon in light of these two challenges.</text>
<text font="5" height="16" left="202" textpieces="1" top="673" width="166">2  The Socioscope</text>
<text font="1" height="13" left="202" textpieces="0" top="713" width="519">We propose Socioscope, a probabilistic model that robustly recovers spatiotem-</text>
<text font="1" height="13" left="202" textpieces="0" top="731" width="519">poral signals from social media data. Formally, consider f de&#64257;ned on discrete</text>
<text font="1" height="13" left="202" textpieces="0" top="749" width="519">spatiotemporal bins. For example, a bin (s, t) could be a U.S. state s on day t,</text>
<text font="1" height="13" left="202" textpieces="0" top="767" width="518">or a county s in hour t. From the &#64257;rst stage we obtain xs,t, the count of tar-</text>
<text font="1" height="13" left="202" textpieces="1" top="785" width="518">get social media posts within that bin. The task is to estimate fs,t from xs,t.</text>
<text font="1" height="13" left="202" textpieces="2" top="806" width="519">A commonly-used estimate is fs,t = xs,t itself. This estimate can be justi&#64257;ed</text>
<text font="1" height="13" left="202" textpieces="0" top="824" width="519">as the maximum likelihood estimate of a Poisson model x &#8764; Poisson(f ). This</text>
<text font="1" height="13" left="202" textpieces="0" top="842" width="519">idea underlines several emerging systems such as earthquake damage monitoring</text>
<text font="1" height="13" left="202" textpieces="0" top="859" width="518">from Twitter [8]. However, this estimate is unsatisfactory since the counts xs,t</text>
<text font="1" height="13" left="202" textpieces="0" top="877" width="519">can be noisy: as mentioned before, the estimate ignores population bias &#8211; more</text>
<text font="1" height="13" left="202" textpieces="0" top="895" width="519">target posts are generated when and where there are more social media users; the</text>
<text font="1" height="13" left="202" textpieces="0" top="913" width="519">location of a target post is frequently inaccurate or missing, making it di&#64259;cult</text>
<text font="1" height="13" left="202" textpieces="0" top="931" width="519">to assign to the correct bin; and target posts can be quite sparse even though</text>
<text font="1" height="13" left="202" textpieces="0" top="949" width="489">the total volume of social media is huge. Socioscope addresses these issues.</text>
<text font="1" height="13" left="225" textpieces="0" top="968" width="496">For notational simplicity, we often denote our signal of interest by a vector</text>
<text font="1" height="13" left="202" textpieces="1" top="986" width="147">f = (f1, . . . , fn)  &#8712; Rn</text>
<text font="2" height="10" left="342" textpieces="0" top="992" width="77">&#8805;0, where fj</text>
<text font="1" height="13" left="425" textpieces="0" top="986" width="296">is a non-negative target phenomenon intensity</text>
<text font="4" height="12" left="282" textpieces="1" top="142" width="439">Socioscope: Spatio-Temporal Signal Recovery from Social Media       3</text>
<text font="1" height="13" left="202" textpieces="0" top="180" width="519">in source bin j = 1 . . . n. We will use a wildlife example throughout the section.</text>
<text font="1" height="13" left="202" textpieces="0" top="198" width="519">In this example, a source bin is a spatiotemporal unit such as &#8220;California, day</text>
<text font="1" height="13" left="202" textpieces="1" top="216" width="518">1,&#8221; and fjis the squirrel activity level in that unit. The mapping between index</text>
<text font="1" height="13" left="202" textpieces="0" top="234" width="478">j and the aforementioned (s, t) is one-one and will be clear from context.</text>
<text font="1" height="13" left="202" textpieces="1" top="279" width="306">2.1  Correcting Human Population Bias</text>
<text font="1" height="13" left="202" textpieces="0" top="310" width="519">For now, assume each target post comes with precise location and time meta</text>
<text font="1" height="13" left="202" textpieces="1" top="328" width="518">data. This allows us to count xj, the number of target posts in bin j. Given xj,</text>
<text font="1" height="13" left="202" textpieces="2" top="349" width="519">it is tempting to use the maximum likelihood estimate fj= xj which assumes a</text>
<text font="1" height="13" left="202" textpieces="2" top="367" width="519">simple Poisson model xj&#8764; Poisson(fj). However, this model is too naive: Even</text>
<text font="1" height="13" left="202" textpieces="1" top="385" width="517">if fj = fk, e.g., the level of squirrel activities is the same in two bins, we would</text>
<text font="1" height="13" left="202" textpieces="2" top="403" width="519">expect xj &gt; xk if there are more people in bin j than in bin k, simply because</text>
<text font="1" height="13" left="202" textpieces="0" top="421" width="290">more people see the same group of squirrels.</text>
<text font="1" height="13" left="225" textpieces="0" top="439" width="496">To account for this population bias, we de&#64257;ne an &#8220;active social media user</text>
<text font="1" height="13" left="202" textpieces="2" top="457" width="544">population intensity&#8221; (loosely called &#8220;human population&#8221; below) g = (g1, . . . , gn)  &#8712;</text>
<text font="1" height="12" left="202" textpieces="2" top="478" width="519">Rn &#8805;0. Let zj be the count of all social media posts in bin j, the vast majority of</text>
<text font="1" height="13" left="202" textpieces="1" top="492" width="518">which are not about the target phenomenon. We assume zj &#8764; Poisson(gj). Since</text>
<text font="1" height="13" left="202" textpieces="3" top="510" width="476">typically zj    0, the maximum likelihood estimate gj= zj is reasonable.</text>
<text font="1" height="13" left="225" textpieces="0" top="529" width="299">Importantly, we then posit the Poisson model</text>
<text font="1" height="13" left="385" textpieces="3" top="562" width="336">xj&#8764; Poisson(&#951;(fj, gj)).                           (1)</text>
<text font="1" height="13" left="202" textpieces="1" top="595" width="518">The intensity is de&#64257;ned by a link function &#951;(fj, gj). In this paper, we simply</text>
<text font="1" height="13" left="202" textpieces="3" top="613" width="519">de&#64257;ne &#951;(fj, gj) = fj &#183; gj but note that other more sophisticated link functions</text>
<text font="1" height="13" left="202" textpieces="2" top="631" width="519">can be learned from data. Given xj and zj, one can then easily estimate fj with</text>
<text font="1" height="13" left="202" textpieces="1" top="651" width="204">the plug-in estimator fj = xj/z</text>
<text font="2" height="9" left="408" textpieces="0" top="657" width="9">j.</text>
<text font="1" height="13" left="202" textpieces="1" top="697" width="321">2.2  Handling Noisy and Incomplete Data</text>
<text font="1" height="13" left="202" textpieces="0" top="728" width="519">This would have been the end of the story if we could reliably assign each post</text>
<text font="1" height="13" left="202" textpieces="0" top="746" width="519">to a source bin. Unfortunately, this is often not the case for social media. In this</text>
<text font="1" height="13" left="202" textpieces="0" top="764" width="519">paper, we focus on the problem of spatial uncertainty due to noisy or incomplete</text>
<text font="1" height="13" left="202" textpieces="0" top="782" width="519">social media data. A prime example of spatial uncertainty is the lack of location</text>
<text font="1" height="13" left="202" textpieces="1" top="800" width="519">meta data in posts from Twitter (called tweets).1 In recent data we collected,</text>
<text font="1" height="13" left="202" textpieces="0" top="818" width="519">only 3% of tweets contain the latitude and longitude at which they were created.</text>
<text font="1" height="13" left="202" textpieces="0" top="836" width="519">Another 47% contain a valid user self-declared location in his or her pro&#64257;le (e.g.,</text>
<text font="1" height="13" left="202" textpieces="0" top="854" width="519">&#8220;New York, NY&#8221;). However, such location does not automatically change while</text>
<text font="1" height="13" left="202" textpieces="0" top="872" width="519">the user travels and thus may not be the true location at which a tweet is posted.</text>
<text font="1" height="13" left="202" textpieces="0" top="890" width="519">The remaining 50% do not contain location at all. Clearly, we cannot reliably</text>
<text font="1" height="13" left="202" textpieces="1" top="908" width="456">assign the latter two kinds of tweets to a spatiotemporal source bin.2</text>
<text font="3" height="8" left="206" textpieces="1" top="935" width="515">1  It may be possible to recover occasional location information from the tweet text</text>
<text font="4" height="12" left="217" textpieces="0" top="954" width="358">itself instead of the meta data, but the problem still exists.</text>
<text font="3" height="8" left="206" textpieces="1" top="968" width="515">2  Another kind of spatiotemporal uncertainty exists in social media even when the local</text>
<text font="4" height="12" left="217" textpieces="0" top="987" width="504">and time meta data of every post is known: social media users may not immediately</text>
<text font="4" height="12" left="202" textpieces="1" top="142" width="328">4       Xu, J., Bhargava, A., Nowak, R., and Zhu, X.</text>
<text font="1" height="13" left="225" textpieces="0" top="180" width="496">To address this issue, we borrow an idea from Positron Emission Tomogra-</text>
<text font="1" height="13" left="202" textpieces="0" top="198" width="519">phy [19]. In particular, we de&#64257;ne m detector bins which are conceptually distinct</text>
<text font="1" height="13" left="202" textpieces="0" top="216" width="519">from the n source bins. The idea is that an event originating in some source bin</text>
<text font="1" height="13" left="202" textpieces="0" top="234" width="519">goes through a transition process and ends up in one of the detector bins, where</text>
<text font="1" height="13" left="202" textpieces="0" top="252" width="515">it is detected. This transition is modeled by an m &#215; n matrix P = {Pij} where</text>
<text font="1" height="13" left="362" textpieces="2" top="289" width="359">Pij= Pr(detector i | source j).                       (2)</text>
<text font="1" height="13" left="202" textpieces="0" top="327" width="151">P is column stochastic:</text>
<text font="2" height="9" left="374" textpieces="0" top="322" width="11">m</text>
<text font="2" height="9" left="374" textpieces="0" top="334" width="19">i=1</text>
<text font="1" height="13" left="396" textpieces="1" top="327" width="324">Pij= 1, &#8704;j. We defer the discussion of our speci&#64257;c</text>
<text font="1" height="13" left="202" textpieces="0" top="345" width="519">P to a case study, but we mention that it is possible to reliably estimate P</text>
<text font="1" height="13" left="202" textpieces="0" top="362" width="519">directly from social media data (more on this later). Recall the target post</text>
<text font="1" height="13" left="202" textpieces="1" top="380" width="518">intensity at source bin j is &#951;(fj, gj). We use the transition matrix to de&#64257;ne the</text>
<text font="1" height="13" left="202" textpieces="2" top="398" width="518">target post intensity hi (note that hi can itself be viewed as a link function</text>
<text font="1" height="13" left="203" textpieces="1" top="416" width="163">&#732; &#951;(f , g)) at detector bin i:</text>
<text font="1" height="13" left="394" textpieces="1" top="466" width="30">hi=</text>
<text font="2" height="9" left="435" textpieces="0" top="450" width="7">n</text>
<text font="2" height="9" left="428" textpieces="0" top="486" width="21">j=1</text>
<text font="1" height="13" left="452" textpieces="2" top="466" width="269">Pij&#951;(fj, gj).                             (3)</text>
<text font="1" height="13" left="225" textpieces="0" top="521" width="496">For the spatial uncertainty that we consider, we create three kinds of detector</text>
<text font="1" height="13" left="202" textpieces="0" top="539" width="519">bins. For a source bin j such as &#8220;California, day 1,&#8221; the &#64257;rst kind collects target</text>
<text font="1" height="13" left="202" textpieces="0" top="557" width="519">posts on day 1 whose latitude and longitude meta data is in California. The</text>
<text font="1" height="13" left="202" textpieces="0" top="574" width="519">second kind collects target posts on day 1 without latitude and longitude meta</text>
<text font="1" height="13" left="202" textpieces="0" top="592" width="519">data, but whose user self-declared pro&#64257;le location is in California. The third kind</text>
<text font="1" height="13" left="202" textpieces="0" top="610" width="519">collects target posts on day 1 without any location information. Note the third</text>
<text font="1" height="13" left="202" textpieces="0" top="628" width="519">kind of detector bin is shared by all other source bins for day 1, such as &#8220;Nevada,</text>
<text font="1" height="13" left="202" textpieces="0" top="646" width="519">day 1,&#8221; too. Consequently, if we had n = 50T source bins corresponding to the</text>
<text font="1" height="13" left="202" textpieces="0" top="664" width="491">50 US states over T days, there would be m = (2 &#215; 50 + 1)T detector bins.</text>
<text font="1" height="13" left="225" textpieces="0" top="684" width="496">Critically, our observed target counts x are now with respect to the m de-</text>
<text font="1" height="13" left="202" textpieces="0" top="702" width="518">tector bins instead of the n source bins: x = (x1, . . . , xm) . We will also denote</text>
<text font="1" height="13" left="202" textpieces="0" top="720" width="518">the count sub-vector for the &#64257;rst kind of detector bins by x(1), the second kind</text>
<text font="1" height="13" left="202" textpieces="1" top="738" width="518">x(2), and the third kind x(3). The same is true for the overall counts z. A trivial</text>
<text font="1" height="13" left="202" textpieces="2" top="756" width="480">approach is to only utilize x(1) and z(1)to arrive at the plug-in estimator</text>
<text font="1" height="13" left="415" textpieces="1" top="796" width="57">fj = x(1)</text>
<text font="2" height="9" left="457" textpieces="0" top="803" width="5">j</text>
<text font="1" height="13" left="473" textpieces="0" top="796" width="29">/z(1)</text>
<text font="2" height="9" left="487" textpieces="0" top="803" width="5">j</text>
<text font="1" height="13" left="504" textpieces="1" top="796" width="217">.                                (4)</text>
<text font="1" height="13" left="202" textpieces="0" top="833" width="519">As we will show, we can obtain a better estimator by incorporating noisy data</text>
<text font="1" height="13" left="202" textpieces="2" top="851" width="519">x(2) and incomplete data x(3). z(1) is su&#64259;ciently large and we will simply ignore</text>
<text font="1" height="13" left="202" textpieces="1" top="869" width="85">z(2) and z(3).</text>
<text font="4" height="12" left="217" textpieces="0" top="904" width="504">post right at the spot where a target phenomenon happens. Instead, there usually</text>
<text font="4" height="12" left="217" textpieces="0" top="921" width="504">is an unknown time delay and spatial shift between the phenomenon and the post</text>
<text font="4" height="12" left="217" textpieces="0" top="937" width="504">generation. For example, one may not post a squirrel encounter on the road until she</text>
<text font="4" height="12" left="217" textpieces="0" top="954" width="504">arrives at home later; the local and time meta data only re&#64258;ects tweet-generation</text>
<text font="4" height="12" left="217" textpieces="0" top="970" width="504">at home. This type of spatiotemporal uncertainty can be addressed by the same</text>
<text font="4" height="12" left="217" textpieces="0" top="987" width="200">source-detector transition model.</text>
<text font="4" height="12" left="282" textpieces="1" top="142" width="439">Socioscope: Spatio-Temporal Signal Recovery from Social Media       5</text>
<text font="1" height="13" left="202" textpieces="1" top="180" width="401">2.3  Socioscope: Penalized Poisson Likelihood Model</text>
<text font="1" height="13" left="202" textpieces="0" top="218" width="518">We observe target post counts x = (x1, . . . , xm) in the detector bins. These are</text>
<text font="1" height="13" left="202" textpieces="0" top="236" width="421">modeled as independently Poisson distributed random variables:</text>
<text font="1" height="13" left="355" textpieces="3" top="272" width="366">xi&#8764; Poisson(hi), for i = 1 . . . m.                      (5)</text>
<text font="1" height="13" left="202" textpieces="0" top="308" width="185">The log likelihood factors as</text>
<text font="1" height="13" left="313" textpieces="0" top="356" width="58">(f ) = log</text>
<text font="2" height="9" left="378" textpieces="0" top="340" width="11">m</text>
<text font="2" height="9" left="373" textpieces="0" top="376" width="19">i=1</text>
<text font="1" height="13" left="397" textpieces="0" top="346" width="20">hxi</text>
<text font="2" height="9" left="406" textpieces="0" top="353" width="4">i</text>
<text font="1" height="13" left="418" textpieces="0" top="346" width="27">e&#8722;hi</text>
<text font="1" height="13" left="413" textpieces="0" top="366" width="17">xi!</text>
<text font="1" height="13" left="453" textpieces="0" top="356" width="12">=</text>
<text font="2" height="9" left="474" textpieces="0" top="340" width="11">m</text>
<text font="2" height="9" left="469" textpieces="0" top="376" width="19">i=1</text>
<text font="1" height="13" left="492" textpieces="3" top="356" width="229">(xilog hi&#8722; hi) + c,              (6)</text>
<text font="1" height="13" left="202" textpieces="0" top="406" width="317">where c is a constant. In (6) we treat g as given.</text>
<text font="1" height="13" left="225" textpieces="0" top="425" width="496">Target posts may be scarce in some detector bins. Indeed, we often have zero</text>
<text font="1" height="13" left="202" textpieces="0" top="443" width="519">target posts for the wildlife case study to be discussed later. This problem can</text>
<text font="1" height="13" left="202" textpieces="0" top="461" width="519">be mitigated by the fact that many real-world phenomena are spatiotemporally</text>
<text font="1" height="13" left="202" textpieces="0" top="479" width="519">smooth, i.e., &#8220;neighboring&#8221; source bins in space or time tend to have similar</text>
<text font="1" height="13" left="202" textpieces="0" top="497" width="519">intensity. We therefore adopt a penalized likelihood approach by constructing a</text>
<text font="1" height="13" left="202" textpieces="0" top="515" width="519">graph-based regularizer. The undirected graph is constructed so that the nodes</text>
<text font="1" height="13" left="202" textpieces="0" top="533" width="519">are the source bins. Let W be the n &#215; n symmetric non-negative weight matrix.</text>
<text font="1" height="13" left="202" textpieces="1" top="551" width="519">The edge weights are such that Wjkis large if j and k correspond to neighboring</text>
<text font="1" height="13" left="202" textpieces="0" top="569" width="519">bins in space and time. Since W is domain speci&#64257;c, we defer its construction to</text>
<text font="1" height="13" left="202" textpieces="0" top="587" width="96">the case study.</text>
<text font="1" height="13" left="225" textpieces="0" top="606" width="496">Before discussing the regularizer, we need to perform a change of variables.</text>
<text font="1" height="13" left="202" textpieces="0" top="624" width="519">Poisson intensity f is non-negative, necessitating a constrained optimization</text>
<text font="1" height="13" left="202" textpieces="0" top="642" width="519">problem. It is more convenient to work with an unconstrained problem. To this</text>
<text font="1" height="13" left="202" textpieces="0" top="660" width="519">end, we work with the exponential family natural parameters of Poisson. Specif-</text>
<text font="1" height="13" left="202" textpieces="0" top="678" width="59">ically, let</text>
<text font="1" height="13" left="382" textpieces="3" top="701" width="339">&#952;j = log fj, &#968;j = log gj.                           (7)</text>
<text font="1" height="13" left="202" textpieces="0" top="733" width="272">Our speci&#64257;c link function becomes &#951;(&#952;j, &#968;</text>
<text font="2" height="9" left="476" textpieces="0" top="738" width="48">j) = e&#952;j</text>
<text font="2" height="9" left="526" textpieces="1" top="731" width="194">+&#968;j. The detector bin intensi-</text>
<text font="1" height="13" left="202" textpieces="1" top="751" width="111">ties become hi=</text>
<text font="2" height="9" left="332" textpieces="0" top="746" width="7">n</text>
<text font="2" height="9" left="332" textpieces="0" top="758" width="21">j=1</text>
<text font="1" height="13" left="356" textpieces="1" top="751" width="79">Pij&#951;(&#952;j, &#968;j).</text>
<text font="1" height="13" left="225" textpieces="0" top="770" width="323">Our graph-based regularizer applies to &#952; directly:</text>
<text font="1" height="13" left="411" textpieces="0" top="813" width="47">&#8486;(&#952;) =</text>
<text font="1" height="13" left="464" textpieces="0" top="803" width="7">1</text>
<text font="1" height="13" left="464" textpieces="0" top="823" width="7">2</text>
<text font="1" height="13" left="473" textpieces="1" top="813" width="248">&#952; L&#952;,                               (8)</text>
<text font="1" height="13" left="202" textpieces="0" top="854" width="519">where L is the combinatorial graph Laplacian [5]: L = D &#8722; W, and D is the</text>
<text font="1" height="13" left="202" textpieces="1" top="872" width="229">diagonal degree matrix with Djj=</text>
<text font="2" height="9" left="451" textpieces="0" top="867" width="7">n</text>
<text font="2" height="9" left="451" textpieces="0" top="879" width="22">k=1</text>
<text font="1" height="13" left="476" textpieces="0" top="872" width="30">Wjk.</text>
<text font="1" height="13" left="225" textpieces="0" top="891" width="496">Finally, Socioscope is the following penalized likelihood optimization prob-</text>
<text font="1" height="13" left="202" textpieces="0" top="909" width="27">lem:</text>
<text font="1" height="13" left="350" textpieces="0" top="941" width="25">min</text>
<text font="2" height="11" left="348" textpieces="0" top="953" width="29">&#952;&#8712;Rn</text>
<text font="1" height="14" left="379" textpieces="0" top="940" width="12">&#8722;</text>
<text font="2" height="9" left="399" textpieces="0" top="925" width="11">m</text>
<text font="2" height="9" left="395" textpieces="0" top="961" width="19">i=1</text>
<text font="1" height="13" left="418" textpieces="3" top="941" width="303">(xilog hi&#8722; hi) + &#955;&#8486;(&#952;),                     (9)</text>
<text font="1" height="13" left="202" textpieces="0" top="986" width="281">where &#955; is a positive regularization weight.</text>
<text font="4" height="12" left="202" textpieces="1" top="142" width="328">6       Xu, J., Bhargava, A., Nowak, R., and Zhu, X.</text>
<text font="1" height="13" left="202" textpieces="1" top="180" width="138">2.4  Optimization</text>
<text font="1" height="13" left="202" textpieces="0" top="207" width="519">We solve the Socioscope optimization problem (9) with BFGS, a quasi-Newton</text>
<text font="1" height="13" left="202" textpieces="0" top="225" width="347">method [14]. The gradient can be easily computed as</text>
<text font="1" height="13" left="398" textpieces="1" top="255" width="323">= &#955;L&#952; &#8722; HP (r &#8722; 1),                         (10)</text>
<text font="1" height="13" left="202" textpieces="3" top="285" width="519">where r = (r1. . . rm) is a ratio vector with ri = xi/hi, and H is a diagonal</text>
<text font="1" height="13" left="202" textpieces="2" top="303" width="187">matrix with Hjj= &#951;(&#952;j, &#968;j).</text>
<text font="1" height="13" left="225" textpieces="0" top="320" width="496">We initialize &#952; with the following heuristic. Given counts x and the transition</text>
<text font="1" height="13" left="202" textpieces="1" top="338" width="518">matrix P , we compute the least-squared projection &#951;0 to x &#8722; P&#951;0 2. This pro-</text>
<text font="1" height="13" left="202" textpieces="1" top="356" width="519">jection is easy to compute. However, &#951;0 may contain negative components not</text>
<text font="1" height="13" left="202" textpieces="1" top="374" width="518">suitable for Poisson intensity. We force positivity by setting &#951;0&#8592; max(10&#8722;4, &#951;0)</text>
<text font="1" height="13" left="202" textpieces="2" top="392" width="519">element-wise, where the &#64258;oor 10&#8722;4 ensures that log &#951;0 &gt; &#8722;&#8734;. From the de&#64257;ni-</text>
<text font="1" height="13" left="202" textpieces="0" top="410" width="412">tion &#951;(&#952;, &#968;) = exp(&#952; + &#968;), we then obtain the initial parameter</text>
<text font="1" height="13" left="410" textpieces="3" top="440" width="311">&#952;0= log &#951;0&#8722; &#968;.                              (11)</text>
<text font="1" height="13" left="225" textpieces="0" top="470" width="496">Our optimization is e&#64259;cient: problems with more than one thousand variables</text>
<text font="1" height="13" left="202" textpieces="0" top="487" width="401">(n) are solved in about 15 seconds with fminunc() in Matlab.</text>
<text font="1" height="13" left="202" textpieces="1" top="530" width="176">2.5  Parameter Tuning</text>
<text font="1" height="13" left="202" textpieces="0" top="557" width="519">The choice of the regularization parameter &#955; has a profound e&#64256;ect on the smooth-</text>
<text font="1" height="13" left="202" textpieces="0" top="575" width="519">ness of the estimates. It may be possible to select these parameters based on prior</text>
<text font="1" height="13" left="202" textpieces="0" top="593" width="519">knowledge in certain problems, but for our experiments we select these param-</text>
<text font="1" height="13" left="202" textpieces="0" top="611" width="519">eters using a cross-validation (CV) procedure, which gives us a fully data-based</text>
<text font="1" height="13" left="202" textpieces="0" top="629" width="269">and objective approach to regularization.</text>
<text font="1" height="13" left="225" textpieces="0" top="647" width="496">CV is quite simple to implement in the Poisson setting. A hold-out set of data</text>
<text font="1" height="13" left="202" textpieces="0" top="665" width="519">can be constructed by simply sub-sampling events from the total observation</text>
<text font="1" height="13" left="202" textpieces="0" top="683" width="519">uniformly at random. This produces a partial data set of a subset of the counts</text>
<text font="1" height="13" left="202" textpieces="0" top="701" width="519">that follows precisely the same distribution as the whole set, modulo a decrease</text>
<text font="1" height="13" left="202" textpieces="0" top="719" width="519">in the total intensity per the level of subsampling. The complement of the hold-</text>
<text font="1" height="13" left="202" textpieces="0" top="736" width="519">out set is what remains of the full dataset, and we will call this the training set.</text>
<text font="1" height="13" left="202" textpieces="0" top="754" width="519">The hold-out set is taken to be a speci&#64257;c fraction of the total. For theoretical</text>
<text font="1" height="13" left="202" textpieces="0" top="772" width="519">reasons beyond the scope of this paper, we do not recommend leave-one-out</text>
<text font="1" height="13" left="202" textpieces="0" top="790" width="69">CV [18, 6].</text>
<text font="1" height="13" left="225" textpieces="0" top="808" width="496">CV is implemented by generating a number of random splits of this type (we</text>
<text font="1" height="13" left="202" textpieces="0" top="826" width="519">can generate as many as we wish), and for each split we run the optimization</text>
<text font="1" height="13" left="202" textpieces="0" top="844" width="519">algorithm above on the training set for a range of values of &#955;. Then compute the</text>
<text font="1" height="13" left="202" textpieces="0" top="862" width="519">(unregularized) value of the log-likelihood on the hold-out set. This provides us</text>
<text font="1" height="13" left="202" textpieces="0" top="880" width="519">with an estimate of the log-likelihood for each setting of &#955;. We simply select the</text>
<text font="1" height="13" left="202" textpieces="0" top="898" width="339">setting that maximizes the estimated log-likelihood.</text>
<text font="1" height="13" left="202" textpieces="1" top="940" width="241">2.6  Theoretical Considerations</text>
<text font="1" height="13" left="202" textpieces="0" top="968" width="519">The natural measure of signal-to-noise in this problem is the number of counts in</text>
<text font="1" height="13" left="202" textpieces="0" top="986" width="519">each bin. The higher the counts, the more stable and &#8220;less noisy&#8221; our estimators</text>
<text font="4" height="12" left="282" textpieces="1" top="142" width="439">Socioscope: Spatio-Temporal Signal Recovery from Social Media       7</text>
<text font="1" height="13" left="202" textpieces="1" top="180" width="517">will be. Indeed, if we directly observe xi&#8764; Poisson(hi), then the normalized error</text>
<text font="1" height="13" left="202" textpieces="1" top="198" width="54">E[(xi&#8722;hi</text>
<text font="2" height="9" left="236" textpieces="0" top="206" width="11">hi</text>
<text font="1" height="13" left="260" textpieces="0" top="198" width="60">)2] = h&#8722;1</text>
<text font="2" height="9" left="305" textpieces="0" top="205" width="4">i</text>
<text font="1" height="14" left="325" textpieces="0" top="197" width="39">&#8776; x&#8722;1</text>
<text font="2" height="9" left="349" textpieces="0" top="205" width="4">i</text>
<text font="1" height="13" left="365" textpieces="0" top="198" width="356">. So larger counts, due to larger underlying intensities,</text>
<text font="1" height="13" left="202" textpieces="0" top="216" width="519">lead to small errors on a relative scale. However, the accuracy of our recovery</text>
<text font="1" height="13" left="202" textpieces="0" top="234" width="519">also depends on the regularity of the underlying function f . If it is very smooth,</text>
<text font="1" height="13" left="202" textpieces="0" top="252" width="519">for example a constant function, then the error would be inversely proportional</text>
<text font="1" height="13" left="202" textpieces="0" top="269" width="519">to the total number of counts, not the number in each individual bin. This is</text>
<text font="1" height="13" left="202" textpieces="0" top="287" width="485">because in the extreme smooth case, f is determined by a single constant.</text>
<text font="1" height="13" left="225" textpieces="0" top="305" width="496">To give some insight into dependence of the estimate on the total number of</text>
<text font="1" height="13" left="202" textpieces="0" top="323" width="519">counts, suppose that f is the underlying continuous intensity function of interest.</text>
<text font="1" height="13" left="202" textpieces="1" top="341" width="519">Furthermore, let f be a H&#168; older &#945;-smooth function. The parameter &#945; is related</text>
<text font="1" height="13" left="202" textpieces="0" top="359" width="519">to the number of continuous derivatives f has. Larger values of &#945; correspond</text>
<text font="1" height="13" left="202" textpieces="0" top="377" width="519">to smoother functions. Such a model is reasonable for the application at hand,</text>
<text font="1" height="13" left="202" textpieces="0" top="395" width="519">as discussed in our motivation for regularization above. We recall the following</text>
<text font="1" height="13" left="202" textpieces="0" top="413" width="411">minimax lower bound, which follows from the results in [7, 20].</text>
<text font="1" height="13" left="202" textpieces="1" top="441" width="519">Theorem 1. Let f be a H&#168; older &#945;-smooth d-dimensional intensity function and</text>
<text font="1" height="13" left="202" textpieces="0" top="459" width="519">suppose we observe N events from the distribution Poisson(f ). Then there exists</text>
<text font="1" height="13" left="202" textpieces="1" top="477" width="184">a constant C&#945;&gt; 0 such that</text>
<text font="1" height="13" left="347" textpieces="0" top="520" width="17">inf</text>
<text font="2" height="5" left="355" textpieces="1" top="539" width="4">b  f</text>
<text font="1" height="13" left="368" textpieces="0" top="520" width="23">sup</text>
<text font="2" height="9" left="375" textpieces="0" top="535" width="6">f</text>
<text font="1" height="13" left="394" textpieces="1" top="509" width="73">E[ f &#8722; f 2</text>
<text font="2" height="9" left="461" textpieces="0" top="516" width="10">1]</text>
<text font="1" height="13" left="425" textpieces="1" top="530" width="23">f 2</text>
<text font="2" height="9" left="442" textpieces="0" top="537" width="6">1</text>
<text font="1" height="14" left="483" textpieces="0" top="519" width="52">&#8805; C&#945;N</text>
<text font="6" height="7" left="541" textpieces="0" top="513" width="20">&#8722;2&#945;</text>
<text font="6" height="7" left="539" textpieces="1" top="522" width="37">2&#945;+d   ,</text>
<text font="1" height="13" left="202" textpieces="0" top="562" width="519">where the in&#64257;mum is over all possible estimators. The error is measured with the</text>
<text font="1" height="13" left="202" textpieces="0" top="580" width="519">1-norm, rather than two norm, which is a more appropriate and natural norm</text>
<text font="1" height="13" left="202" textpieces="0" top="598" width="519">in density and intensity estimation. The theorem tells us that no estimator can</text>
<text font="1" height="13" left="202" textpieces="0" top="616" width="519">achieve a faster rate of error decay than the bound above. There exist many</text>
<text font="1" height="13" left="202" textpieces="0" top="634" width="519">types of estimators that nearly achieve this bound (e.g., to within a log factor),</text>
<text font="1" height="13" left="202" textpieces="0" top="652" width="519">and with more work it is possible to show that our regularized estimators, with</text>
<text font="1" height="13" left="202" textpieces="0" top="670" width="519">adaptively chosen bin sizes and appropriate regularization parameter settings,</text>
<text font="1" height="13" left="202" textpieces="0" top="688" width="519">could also nearly achieve this rate. For the purposes of this discussion, the lower</text>
<text font="1" height="13" left="202" textpieces="0" top="706" width="388">bound, which certainly applies to our situation, will su&#64259;ce.</text>
<text font="1" height="13" left="225" textpieces="0" top="724" width="496">For example, consider just two spatial dimensions (d = 2) and &#945; = 1 which</text>
<text font="1" height="13" left="202" textpieces="0" top="741" width="519">corresponds to Lipschitz smooth functions, a very mild regularity assumption.</text>
<text font="1" height="13" left="202" textpieces="1" top="759" width="519">Then the bound says that the error is proportional to N&#8722;1/2. This gives useful</text>
<text font="1" height="13" left="202" textpieces="0" top="777" width="519">insight into the minimal data requirements of our methods. It tells us, for exam-</text>
<text font="1" height="13" left="202" textpieces="0" top="795" width="519">ple, that if we want to reduce the error of the estimator by a factor of say 2, then</text>
<text font="1" height="13" left="202" textpieces="0" top="813" width="519">the total number of counts must be increased by a factor of 4. If the smoothness</text>
<text font="1" height="13" left="202" textpieces="0" top="831" width="519">&#945; is very large, then doubling the counts can halve the error. The message is</text>
<text font="1" height="13" left="202" textpieces="0" top="849" width="500">simple. More events and higher counts will provide more accurate estimates.</text>
<text font="5" height="16" left="202" textpieces="1" top="894" width="153">3  Related Work</text>
<text font="1" height="13" left="202" textpieces="0" top="932" width="519">To our knowledge, there is no comparable prior work that focuses on robust</text>
<text font="1" height="13" left="202" textpieces="0" top="950" width="519">single recovery from social media (i.e., the &#8220;second stage&#8221; as we mentioned in</text>
<text font="1" height="13" left="202" textpieces="0" top="968" width="519">the introduction). However, there has been considerable related work on the &#64257;rst</text>
<text font="1" height="13" left="202" textpieces="0" top="986" width="224">stage, which we summarize below.</text>
<text font="4" height="12" left="202" textpieces="1" top="142" width="328">8       Xu, J., Bhargava, A., Nowak, R., and Zhu, X.</text>
<text font="1" height="13" left="225" textpieces="0" top="180" width="496">Topic detection and tracking (TDT) aims at identifying emerging topics from</text>
<text font="1" height="13" left="202" textpieces="0" top="198" width="519">text stream and grouping documents based on their topics. The early work in</text>
<text font="1" height="13" left="202" textpieces="0" top="216" width="519">this direction began with news text streamed from newswire and transcribed</text>
<text font="1" height="13" left="202" textpieces="0" top="234" width="519">from other media [1]. Recent research focused on user-generated content on</text>
<text font="1" height="13" left="202" textpieces="0" top="252" width="519">the web and on the spatio-temporal variation of topics. Latent Dirichlet Al-</text>
<text font="1" height="13" left="202" textpieces="0" top="269" width="519">location (LDA) [3] is a popular unsupervised method to detect topics. Mei</text>
<text font="1" height="13" left="202" textpieces="0" top="287" width="519">et al. [12] extended LDA by taking spatio-temporal context into account to iden-</text>
<text font="1" height="13" left="202" textpieces="0" top="305" width="519">tify subtopics from weblogs. They analyzed the spatio-temporal pattern of topic</text>
<text font="1" height="13" left="202" textpieces="0" top="323" width="519">&#952; by Pr(time|&#952;, location) and Pr(location|&#952;, time), and showed that documents</text>
<text font="1" height="13" left="202" textpieces="0" top="341" width="519">created from the same spatio-temporal context tend to share topics. In the same</text>
<text font="1" height="13" left="202" textpieces="0" top="359" width="519">spirit, Yin et al. [22] studied GPS-associated documents, whose coordinates are</text>
<text font="1" height="13" left="202" textpieces="0" top="377" width="519">generated by Gaussian Mixture Model in their generative framework. Cataldi</text>
<text font="1" height="13" left="202" textpieces="0" top="395" width="519">et al. [4] proposed a feature-pivot method. They &#64257;rst identi&#64257;ed keywords whose</text>
<text font="1" height="13" left="202" textpieces="0" top="413" width="519">occurrences dramatically increase in a speci&#64257;ed time interval and then connected</text>
<text font="1" height="13" left="202" textpieces="0" top="431" width="519">the keywords to detect emerging topics. Besides text, social network structure</text>
<text font="1" height="13" left="202" textpieces="0" top="449" width="519">also provides important information for detecting community-based topics and</text>
<text font="1" height="13" left="202" textpieces="0" top="467" width="90">user interests.</text>
<text font="1" height="13" left="225" textpieces="0" top="486" width="496">Event detection is highly related to TDT. Yang et al. [21] uses clustering</text>
<text font="1" height="13" left="202" textpieces="0" top="504" width="519">algorithm to identify events from news streams. Others tried to distinguish posts</text>
<text font="1" height="13" left="202" textpieces="0" top="522" width="519">related to real world events from posts about non-events, such as describing</text>
<text font="1" height="13" left="202" textpieces="0" top="540" width="519">daily life or emotions [2]. Real world events were also detected in Flickr photos</text>
<text font="1" height="13" left="202" textpieces="0" top="558" width="519">with meta information and Twitter. Other researchers were interested in events</text>
<text font="1" height="13" left="202" textpieces="0" top="576" width="519">with special characteristics, such as controversial events and local events. Sakaki</text>
<text font="1" height="13" left="202" textpieces="0" top="594" width="519">et al. [16] monitored Twitter to detect real-time events such as earthquakes and</text>
<text font="1" height="13" left="202" textpieces="0" top="612" width="71">hurricanes.</text>
<text font="1" height="13" left="225" textpieces="0" top="632" width="496">Another line of related work uses social media as a data source to answer</text>
<text font="1" height="13" left="202" textpieces="0" top="650" width="519">scienti&#64257;c questions [11]. Most previous work studied questions in linguistic, so-</text>
<text font="1" height="13" left="202" textpieces="0" top="667" width="519">ciology and human interactions. For example, Eisenstein et al. [9] studied the</text>
<text font="1" height="13" left="202" textpieces="0" top="685" width="519">geographic linguistic variation with geotagged social media. Gupte et al. [10]</text>
<text font="1" height="13" left="202" textpieces="0" top="703" width="435">studied social hierarchy and strati&#64257;cation in online social network.</text>
<text font="1" height="13" left="225" textpieces="0" top="723" width="496">As stated earlier, Socioscope di&#64256;ers from past work in its focus on robust</text>
<text font="1" height="13" left="202" textpieces="0" top="741" width="519">signal recovery on prede&#64257;ned target phenomena. The target posts may be gen-</text>
<text font="1" height="13" left="202" textpieces="0" top="759" width="519">erated at a very low, though sustained, rate, and are corrupted by noise. The</text>
<text font="1" height="13" left="202" textpieces="0" top="777" width="509">above approaches are unlikely to estimate the underlying intensity accurately.</text>
<text font="5" height="16" left="202" textpieces="1" top="831" width="245">4  A Synthetic Experiment</text>
<text font="1" height="13" left="202" textpieces="0" top="878" width="519">We start with a synthetic experiment whose known ground-truth intensity f al-</text>
<text font="1" height="13" left="202" textpieces="0" top="896" width="519">lows us to quantitatively evaluate the e&#64256;ectiveness of Socioscope. The synthetic</text>
<text font="1" height="13" left="202" textpieces="0" top="914" width="519">experiment matches the case study in the next section. There are 48 US con-</text>
<text font="1" height="13" left="202" textpieces="0" top="932" width="519">tinental states plus Washington DC, and T = 24 hours. This leads to a total</text>
<text font="1" height="13" left="202" textpieces="0" top="950" width="519">of n = 1176 source bins, and m = (2 &#215; 49 + 1)T = 2376 detector bins. The</text>
<text font="1" height="13" left="202" textpieces="0" top="968" width="519">transition matrix P is the same as in the case study, to be discussed later. The</text>
<text font="1" height="13" left="202" textpieces="0" top="986" width="447">overall counts z are obtained from actual Twitter data and g = z(1).</text>
<text font="4" height="12" left="282" textpieces="1" top="142" width="439">Socioscope: Spatio-Temporal Signal Recovery from Social Media       9</text>
<text font="1" height="13" left="225" textpieces="0" top="180" width="496">We design the ground-truth target signal f to be temporally constant but</text>
<text font="1" height="13" left="202" textpieces="0" top="198" width="519">spatially varying. Figure 1(a) shows the ground-truth f spatially. It is a mixture</text>
<text font="1" height="13" left="202" textpieces="0" top="216" width="519">of two Gaussian distributions discretized at the state level. The modes are in</text>
<text font="1" height="13" left="202" textpieces="0" top="234" width="519">Washington and New York, respectively. From P, f and g, we generate the</text>
<text font="1" height="13" left="202" textpieces="0" top="252" width="519">observed target post counts for each detector bin by a Poisson random number</text>
<text font="1" height="13" left="202" textpieces="1" top="269" width="161">generator: xi &#8764; Poisson(</text>
<text font="2" height="9" left="379" textpieces="0" top="265" width="7">n</text>
<text font="2" height="9" left="379" textpieces="0" top="277" width="21">j=1</text>
<text font="1" height="13" left="403" textpieces="2" top="269" width="317">Pi,jfjgj), i = 1 . . . m. The sum of counts in x(1)</text>
<text font="1" height="13" left="202" textpieces="2" top="291" width="236">is 56, in x(2) 1106, and in x(3)1030.</text>
<text font="4" height="12" left="329" textpieces="1" top="358" width="264">(i) scaled x(1)                           14.11</text>
<text font="4" height="12" left="329" textpieces="1" top="376" width="264">(ii) scaled x(1)/z(1)                     46.73</text>
<text font="4" height="12" left="329" textpieces="1" top="393" width="265">(iii) Socioscope with x(1)                0.17</text>
<text font="4" height="12" left="329" textpieces="2" top="410" width="265">(iv) Socioscope with x(1)+ x(2)         1.83</text>
<text font="4" height="12" left="329" textpieces="1" top="428" width="265">(v) Socioscope with x(1), x(2)           0.16</text>
<text font="4" height="12" left="329" textpieces="2" top="445" width="264">(vi) Socioscope with x(1), x(2), x(3) 0.12</text>
<text font="4" height="12" left="321" textpieces="0" top="461" width="281">Table 1. Relative error of di&#64256;erent estimators</text>
<text font="1" height="13" left="225" textpieces="4" top="529" width="496">Given x, P, g, We compare the relative error f &#8722; &#710; f 2/ f 2 of several estima-</text>
<text font="1" height="13" left="202" textpieces="0" top="547" width="100">tors in Table 1:</text>
<text font="1" height="13" left="225" textpieces="1" top="573" width="90">(i) &#710; f = x(1)/(</text>
<text font="2" height="9" left="322" textpieces="0" top="579" width="6">1</text>
<text font="1" height="13" left="350" textpieces="0" top="573" width="77">z(1)), where</text>
<text font="2" height="9" left="440" textpieces="0" top="579" width="6">1</text>
<text font="1" height="13" left="453" textpieces="0" top="573" width="268">is the fraction of tweets with precise lo-</text>
<text font="1" height="13" left="202" textpieces="0" top="591" width="519">cation stamp (discussed later in case study). Scaling matches it to the other</text>
<text font="1" height="13" left="202" textpieces="0" top="609" width="519">estimators. Figure 1(b) shows this simple estimator, aggregated spatially. It is</text>
<text font="1" height="13" left="202" textpieces="0" top="627" width="519">a poor estimator: besides being non-smooth, it contains 32 &#8220;holes&#8221; (states with</text>
<text font="1" height="13" left="202" textpieces="1" top="648" width="419">zero intensity, colored in blue) due to data scarcity. (ii) &#710; f = x(1)</text>
<text font="2" height="9" left="606" textpieces="0" top="655" width="5">j</text>
<text font="1" height="13" left="622" textpieces="0" top="648" width="13">/(</text>
<text font="2" height="9" left="642" textpieces="2" top="653" width="79">1z(1)   j  ) which</text>
<text font="1" height="13" left="202" textpieces="0" top="666" width="519">naively corrects the population bias as discussed in (4). It is even worse than</text>
<text font="1" height="13" left="202" textpieces="0" top="684" width="519">the simple estimator, because naive bin-wise correction magni&#64257;es the variance</text>
<text font="1" height="13" left="202" textpieces="0" top="702" width="91">in sparse x(1).</text>
<text font="1" height="13" left="225" textpieces="1" top="728" width="495">(iii) Socioscope with x(1)only. This simulates the practice of discarding noisy</text>
<text font="1" height="13" left="202" textpieces="0" top="746" width="519">or incomplete data, but regularizing for smoothness. The relative error was re-</text>
<text font="1" height="13" left="202" textpieces="0" top="764" width="128">duced dramatically.</text>
<text font="1" height="13" left="225" textpieces="2" top="790" width="495">(iv) Same as (iii) but replace the values of x(1)with x(1)+x(2). This simulates</text>
<text font="1" height="13" left="202" textpieces="1" top="808" width="519">the practice of ignoring the noise in x(2) and pretending it is precise. The result</text>
<text font="1" height="13" left="202" textpieces="0" top="826" width="519">is worse than (iii), indicating that simply including noisy data may hurt the</text>
<text font="1" height="13" left="202" textpieces="0" top="844" width="72">estimation.</text>
<text font="1" height="13" left="225" textpieces="3" top="870" width="496">(v) Socioscope with x(1)and x(2)separately, where x(2) is treated as noisy by</text>
<text font="1" height="13" left="202" textpieces="0" top="888" width="519">P. It reduces the relative error further, and demonstrates the bene&#64257;ts of treating</text>
<text font="1" height="13" left="202" textpieces="0" top="906" width="131">noisy data specially.</text>
<text font="1" height="13" left="225" textpieces="0" top="932" width="496">(vi) Socioscope with the full x. It achieves the lowest relative error among</text>
<text font="1" height="13" left="202" textpieces="0" top="950" width="519">all methods, and is the closest to the ground truth (Figure 1(c)). Compared to</text>
<text font="1" height="13" left="202" textpieces="1" top="968" width="518">(v), this demonstrates that even counts x(3) without location can also help us</text>
<text font="1" height="13" left="202" textpieces="0" top="986" width="125">to recover f better.</text>
<text font="4" height="12" left="202" textpieces="1" top="142" width="328">10      Xu, J., Bhargava, A., Nowak, R., and Zhu, X.</text>
<text font="4" height="12" left="246" textpieces="2" top="300" width="418">(a) ground-truth f           (b) scaled x(1)             (c) Socioscope</text>
<text font="4" height="12" left="361" textpieces="0" top="331" width="201">Fig. 1. The synthetic experiment</text>
<text font="5" height="16" left="202" textpieces="1" top="379" width="216">5  Case Study: Roadkill</text>
<text font="1" height="13" left="202" textpieces="0" top="417" width="519">We were unaware of public benchmark data sets to test robust signal recovery</text>
<text font="1" height="13" left="202" textpieces="0" top="435" width="519">from social media (the &#8220;second stage&#8221;). Several social media datasets were re-</text>
<text font="1" height="13" left="202" textpieces="0" top="453" width="519">leased recently, such as the ICWSM data challenges and the TREC microblog</text>
<text font="1" height="13" left="202" textpieces="0" top="471" width="519">track. These datasets were intended to study trending &#8220;hot topics&#8221; such as the</text>
<text font="1" height="13" left="202" textpieces="0" top="489" width="519">Arabic Spring, Olympic Games, or presidential elections. They are not suitable</text>
<text font="1" height="13" left="202" textpieces="0" top="507" width="519">for low intensity sustained target phenomena which is the focus of our approach.</text>
<text font="1" height="13" left="202" textpieces="0" top="525" width="519">In particular, these datasets do not contain ground-truth spatio-temporal in-</text>
<text font="1" height="13" left="202" textpieces="0" top="543" width="519">tensities and are thus not appropriate testbeds for the problems we are trying</text>
<text font="1" height="13" left="202" textpieces="0" top="561" width="519">to address. Instead, we report a real-world case study on the spatio-temporal</text>
<text font="1" height="13" left="202" textpieces="0" top="579" width="494">intensity of roadkill for several common wildlife species from Twitter posts.</text>
<text font="1" height="13" left="225" textpieces="0" top="597" width="496">The study of roadkill has values in ecology, conservation, and transportation</text>
<text font="1" height="13" left="202" textpieces="0" top="615" width="519">safety. The target phenomenon consists of roadkill events for a speci&#64257;c species</text>
<text font="1" height="13" left="202" textpieces="0" top="632" width="519">within the continental United States during September 22&#8211;November 30, 2011.</text>
<text font="1" height="13" left="202" textpieces="0" top="650" width="519">Our spatio-temporal source bins are state&#215;hour-of-day. Let s index the 48 con-</text>
<text font="1" height="13" left="202" textpieces="0" top="668" width="519">tinental US states plus District of Columbia. We aggregate the 10-week study</text>
<text font="1" height="13" left="202" textpieces="0" top="686" width="519">period into 24 hours of a day. The target counts x are still sparse even with</text>
<text font="1" height="13" left="202" textpieces="0" top="704" width="519">aggregation: for example, most state-hour combination have zero counts for ar-</text>
<text font="1" height="13" left="202" textpieces="2" top="722" width="519">madillo and the largest count in x(1) and x(2) is 3. Therefore, recovering the</text>
<text font="1" height="13" left="202" textpieces="0" top="740" width="519">underlying signal f remains a challenge. Let t index the hours from 1 to 24. This</text>
<text font="1" height="13" left="202" textpieces="0" top="758" width="519">results in |s| = 49, |t| = 24, n = |s||t| = 1176, m = (2|s| + 1)|t| = 2376. We will</text>
<text font="1" height="13" left="202" textpieces="0" top="776" width="519">often index source or detector bins by the subscript (s, t), in addition to i or j,</text>
<text font="1" height="13" left="202" textpieces="0" top="794" width="274">below. The translation should be obvious.</text>
<text font="1" height="13" left="202" textpieces="1" top="839" width="171">5.1  Data Preparation</text>
<text font="1" height="13" left="202" textpieces="0" top="869" width="519">We chose Twitter as our data source because public tweets can be easily collected</text>
<text font="1" height="13" left="202" textpieces="0" top="887" width="519">through its APIs. All tweets include time meta data. However, most tweets do</text>
<text font="1" height="13" left="202" textpieces="0" top="905" width="340">not contain location meta data, as discussed earlier.</text>
<text font="1" height="13" left="202" textpieces="1" top="950" width="519">Overall Counts z(1) and Human Population Intensity g. To obtain the</text>
<text font="1" height="13" left="202" textpieces="0" top="968" width="519">overall counts z, we collected tweets through the Twitter stream API using</text>
<text font="1" height="13" left="202" textpieces="0" top="986" width="519">bounding boxes covering continental US. The API supplied a subsample of all</text>
<text font="4" height="12" left="282" textpieces="1" top="142" width="439">Socioscope: Spatio-Temporal Signal Recovery from Social Media      11</text>
<text font="4" height="12" left="286" textpieces="0" top="299" width="18">(a)</text>
<text font="4" height="6" left="309" textpieces="0" top="308" width="8">b</text>
<text font="4" height="12" left="309" textpieces="2" top="299" width="350">g                    (b) spatial                (c) temporal</text>
<text font="4" height="12" left="345" textpieces="0" top="330" width="217">Fig. 2. Human population intensity</text>
<text font="4" height="6" left="566" textpieces="0" top="339" width="8">b</text>
<text font="4" height="12" left="566" textpieces="0" top="330" width="12">g.</text>
<text font="1" height="13" left="202" textpieces="0" top="381" width="519">tweets (not just target posts) with geo-tag. Therefore, all these tweets include</text>
<text font="1" height="13" left="202" textpieces="0" top="399" width="519">precise latitude and longitude on where they were created. Through a reverse</text>
<text font="1" height="14" left="202" textpieces="0" top="417" width="519">geocoding database (http://www.datasciencetoolkit.org), we mapped the</text>
<text font="1" height="13" left="202" textpieces="0" top="435" width="519">coordinates to a US state. There are a large number of such tweets. Counting the</text>
<text font="1" height="13" left="202" textpieces="0" top="453" width="518">number of tweets in each state-hour bin gave us z(1), from which g is estimated.</text>
<text font="1" height="13" left="225" textpieces="0" top="471" width="496">Figure 2 shows the estimated g. The x-axis is hour of day and y-axis is</text>
<text font="1" height="13" left="202" textpieces="0" top="489" width="519">the states, ordered by longitude from east (top) to west (bottom). Although</text>
<text font="1" height="13" left="202" textpieces="0" top="507" width="519">g in this matrix form contains full information, it can be hard to interpret.</text>
<text font="1" height="13" left="202" textpieces="0" top="525" width="519">Therefore, we visualize aggregated results as well: First, we aggregate out time</text>
<text font="1" height="13" left="202" textpieces="0" top="543" width="231">in g: for each state s, we compute</text>
<text font="2" height="9" left="455" textpieces="0" top="539" width="12">24</text>
<text font="2" height="9" left="455" textpieces="0" top="551" width="20">t=1</text>
<text font="1" height="13" left="478" textpieces="1" top="543" width="243">gs,t and show the resulting intensity</text>
<text font="1" height="13" left="202" textpieces="0" top="561" width="519">maps in Figure 2(b). Second, we aggregate out state in g: for each hour of day</text>
<text font="1" height="13" left="202" textpieces="0" top="580" width="94">t, we compute</text>
<text font="2" height="9" left="318" textpieces="0" top="576" width="12">49</text>
<text font="2" height="9" left="318" textpieces="0" top="588" width="21">s=1</text>
<text font="1" height="13" left="342" textpieces="1" top="580" width="379">gs,t and show the daily curve in Figure 2(c). From these</text>
<text font="1" height="13" left="202" textpieces="0" top="598" width="519">two plots, we clearly see that human population intensity varies greatly both</text>
<text font="1" height="13" left="202" textpieces="0" top="616" width="163">spatially and temporally.</text>
<text font="1" height="13" left="202" textpieces="0" top="662" width="519">Identifying Target Posts to Obtain Counts x. To produce the target counts</text>
<text font="1" height="13" left="202" textpieces="0" top="680" width="519">x, we need to &#64257;rst identify target posts describing roadkill events. Although not</text>
<text font="1" height="13" left="202" textpieces="0" top="698" width="500">part of Socioscope, we detail this preprocessing step here for reproducibility.</text>
<text font="1" height="13" left="225" textpieces="0" top="716" width="496">In step 1, we collected tweets using a keyword API. Each tweet must contain</text>
<text font="1" height="13" left="202" textpieces="0" top="734" width="519">the wildlife name (e.g., &#8220;squirrel(s)&#8221;) and the phrase &#8220;ran over&#8221;. We obtained</text>
<text font="1" height="13" left="202" textpieces="0" top="752" width="519">5857 squirrel tweets, 325 chipmunk tweets, 180 opossum tweets and 159 armadillo</text>
<text font="1" height="13" left="202" textpieces="0" top="770" width="519">tweets during the study period. However, many such tweets did not actually</text>
<text font="1" height="13" left="202" textpieces="0" top="788" width="519">describe roadkill events. For example, &#8220;I almost ran over an armadillo on my</text>
<text font="1" height="13" left="202" textpieces="0" top="806" width="519">longboard, luckily my cat-like re&#64258;exes saved me.&#8221; Clearly, the author did not kill</text>
<text font="1" height="13" left="202" textpieces="0" top="824" width="91">the armadillo.</text>
<text font="1" height="13" left="225" textpieces="0" top="842" width="496">In step 2, we built a binary text classi&#64257;er to identify target posts among them.</text>
<text font="1" height="13" left="202" textpieces="0" top="860" width="519">Following [17], the tweets were case-folded without any stemming or stopword</text>
<text font="1" height="13" left="202" textpieces="0" top="878" width="519">removal. Any user mentions preceded by a &#8220;@&#8221; were replaced by the anonymized</text>
<text font="1" height="13" left="202" textpieces="0" top="896" width="519">user name &#8220;@USERNAME&#8221;. Any URLs staring with &#8220;http&#8221; were replaced by</text>
<text font="1" height="13" left="202" textpieces="0" top="914" width="519">the token &#8220;HTTPLINK&#8221;. Hashtags (compound words following &#8220;#&#8221;) were not</text>
<text font="1" height="13" left="202" textpieces="0" top="932" width="519">split and were treated as a single token. Emoticons, such as &#8220;:)&#8221; or &#8220;:D&#8221;, were</text>
<text font="1" height="13" left="202" textpieces="0" top="950" width="519">also included as tokens. Each tweet is then represented by a feature vector con-</text>
<text font="1" height="13" left="202" textpieces="0" top="968" width="519">sisting of unigram and bigram counts. If any unigram or bigram included animal</text>
<text font="1" height="13" left="202" textpieces="0" top="986" width="519">names, we added an additional feature by replacing the animal name with the</text>
<text font="4" height="12" left="202" textpieces="1" top="142" width="328">12      Xu, J., Bhargava, A., Nowak, R., and Zhu, X.</text>
<text font="1" height="13" left="202" textpieces="0" top="180" width="519">generic token &#8220;ANIMAL&#8221;. For example, we would created an extra feature &#8220;over</text>
<text font="1" height="13" left="202" textpieces="0" top="198" width="519">ANIMAL&#8221; for the bigram &#8220;over raccoon&#8221;. The training data consists of 1,450</text>
<text font="1" height="13" left="202" textpieces="0" top="216" width="519">manually labeled tweets in August 2011 (i.e., outside our study period). These</text>
<text font="1" height="13" left="202" textpieces="0" top="234" width="519">training tweets contain hundreds of animal species, not just the target species.</text>
<text font="1" height="13" left="202" textpieces="0" top="252" width="519">The binary label is whether the tweet is a true &#64257;rst-hand roadkill experience.</text>
<text font="1" height="13" left="202" textpieces="0" top="269" width="519">We trained a linear Support Vector Machine (SVM). The CV accuracy is nearly</text>
<text font="1" height="13" left="202" textpieces="0" top="287" width="519">90%. We then applied this SVM to classify tweets surviving step 1. Those tweets</text>
<text font="1" height="13" left="202" textpieces="0" top="305" width="353">receiving a positive label were treated as target posts.</text>
<text font="1" height="13" left="225" textpieces="1" top="324" width="496">In step 3, we produce x(1), x(2), x(3) counts. Because these target tweets were</text>
<text font="1" height="13" left="202" textpieces="0" top="342" width="519">collected by the keyword API, the nature of the Twitter API means that most</text>
<text font="1" height="13" left="202" textpieces="0" top="360" width="519">do not contain precise location information. As mentioned earlier, only 3% of</text>
<text font="1" height="13" left="202" textpieces="0" top="378" width="519">them contain coordinates. We processed this 3% by the same reverse geocoding</text>
<text font="1" height="13" left="202" textpieces="0" top="398" width="452">database to map them to a US state s, and place them in the x(1)</text>
<text font="2" height="9" left="639" textpieces="0" top="405" width="14">s,t</text>
<text font="1" height="13" left="661" textpieces="0" top="398" width="60">detection</text>
<text font="1" height="13" left="202" textpieces="0" top="416" width="519">bins. 47% of the target posts do not contain coordinates but can be mapped to</text>
<text font="1" height="13" left="202" textpieces="0" top="436" width="518">a US state from user self-declared pro&#64257;le location. These are placed in the x(2)</text>
<text font="2" height="9" left="705" textpieces="0" top="443" width="14">s,t</text>
<text font="1" height="13" left="202" textpieces="0" top="454" width="519">detection bins. The remaining 50% contained no location meta data, and were</text>
<text font="1" height="13" left="202" textpieces="0" top="474" width="113">placed in the x(3)</text>
<text font="2" height="9" left="300" textpieces="0" top="481" width="5">t</text>
<text font="1" height="13" left="321" textpieces="1" top="474" width="107">detection bins.3</text>
<text font="1" height="13" left="202" textpieces="0" top="524" width="519">Constructing the Transition Matrix P. In this study, P characterizes the</text>
<text font="1" height="13" left="202" textpieces="0" top="541" width="519">fraction of tweets which were actually generated in source bin (s, t) end up in</text>
<text font="1" height="13" left="202" textpieces="1" top="559" width="519">the three detector bins: precise location st(1), potentially noisy location st(2),</text>
<text font="1" height="13" left="202" textpieces="0" top="577" width="321">and missing location t(3). We de&#64257;ne P as follows:</text>
<text font="1" height="13" left="225" textpieces="2" top="596" width="496">P(s,t)(1),(s,t) = 0.03, and P(r,t)(1),(s,t) = 0 for &#8704;r = s to re&#64258;ect the fact that</text>
<text font="1" height="13" left="202" textpieces="0" top="616" width="333">we know precisely 3% of the target posts&#8217; location.</text>
<text font="1" height="13" left="225" textpieces="2" top="635" width="496">P(r,t)(2),(s,t)= 0.47Mr,s for all r, s. M is a 49 &#215; 49 &#8220;mis-self-declare&#8221; matrix.</text>
<text font="1" height="13" left="202" textpieces="1" top="653" width="519">Mr,s is the probability that a user self-declares in her pro&#64257;le that she is in state r,</text>
<text font="1" height="13" left="202" textpieces="0" top="671" width="519">but her post is in fact generated in state s. We estimated M from a separate large</text>
<text font="1" height="13" left="202" textpieces="0" top="689" width="519">set of tweets with both coordinates and self-declared pro&#64257;le locations. The M</text>
<text font="1" height="13" left="202" textpieces="0" top="707" width="519">matrix is asymmetric and interesting in its own right: many posts self-declared</text>
<text font="1" height="13" left="202" textpieces="0" top="725" width="519">in California or New York were actually produced all over the country; many</text>
<text font="1" height="13" left="202" textpieces="0" top="743" width="519">self-declared in Washington DC were actually produced in Maryland or Virgina;</text>
<text font="1" height="13" left="202" textpieces="0" top="761" width="519">more posts self-declare Wisconsin but were actually in Illinois than the other</text>
<text font="1" height="13" left="202" textpieces="0" top="778" width="80">way around.</text>
<text font="1" height="13" left="225" textpieces="1" top="797" width="496">Pt(3),(s,t) = 0.50. This aggregates tweets with missing information into the</text>
<text font="1" height="13" left="202" textpieces="0" top="815" width="177">third kind of detector bins.</text>
<text font="1" height="13" left="202" textpieces="0" top="865" width="519">Specifying the Graph Regularizer. Our graph has two kinds of edges. Tem-</text>
<text font="1" height="13" left="202" textpieces="0" top="883" width="519">poral edges connect source bins with the same state and adjacent hours by weight</text>
<text font="1" height="13" left="202" textpieces="0" top="901" width="519">wt. Spatial edges connect source bins with the same hour and adjacent states by</text>
<text font="1" height="13" left="202" textpieces="1" top="919" width="519">weight ws. The regularization weight &#955; was absorbed into wtand ws. We tuned</text>
<text font="1" height="13" left="202" textpieces="3" top="937" width="471">the weights wtand wswith CV on the 2D grid {10&#8722;3, 10&#8722;2.5, . . . , 103}2.</text>
<text font="3" height="8" left="206" textpieces="1" top="968" width="515">3  There were actually only a fraction of all tweets without location which came from</text>
<text font="4" height="12" left="217" textpieces="0" top="987" width="393">all over the world. We estimated this US/World fraction using z.</text>
<text font="4" height="12" left="282" textpieces="1" top="142" width="439">Socioscope: Spatio-Temporal Signal Recovery from Social Media      13</text>
<text font="1" height="13" left="202" textpieces="1" top="180" width="94">5.2  Results</text>
<text font="1" height="13" left="202" textpieces="0" top="206" width="519">We present results on four animals: armadillos, chipmunks, squirrels, opossums.</text>
<text font="1" height="13" left="202" textpieces="0" top="224" width="519">Perhaps surprisingly, precise roadkill intensities for these animals are apparently</text>
<text font="1" height="13" left="202" textpieces="0" top="242" width="519">unknown to science (This serves as a good example of the value Socioscope may</text>
<text font="1" height="13" left="202" textpieces="0" top="260" width="519">provide to wildlife scientists). Instead, domain experts were only able to provide</text>
<text font="1" height="13" left="202" textpieces="0" top="278" width="519">a range map of each animal, see the left column in Figure 3. These maps indicate</text>
<text font="1" height="13" left="202" textpieces="0" top="296" width="519">presence/absence only, and were extracted from NatureServe [15]. In addition,</text>
<text font="1" height="13" left="202" textpieces="0" top="314" width="519">the experts de&#64257;ned armadillo and opossum as nocturnal, chipmunk as diurnal,</text>
<text font="1" height="13" left="202" textpieces="0" top="331" width="519">and squirrels as both crepuscular (active primarily during twilight) and diurnal.</text>
<text font="1" height="13" left="202" textpieces="0" top="349" width="519">Due to the lack of quantitative ground-truth, our comparison will necessarily be</text>
<text font="1" height="13" left="202" textpieces="0" top="367" width="138">qualitative in nature.</text>
<text font="1" height="13" left="225" textpieces="0" top="385" width="496">Socioscope provides sensible estimates on these animals. For example, Fig-</text>
<text font="1" height="13" left="202" textpieces="2" top="403" width="519">ure 4(a) shows counts x(1)+ x(2)for chipmunks which is very sparse (the largest</text>
<text font="1" height="13" left="202" textpieces="0" top="423" width="519">count in any bin is 3), and Figure 4(b) the Socioscope estimate f . The axes are</text>
<text font="1" height="13" left="202" textpieces="0" top="441" width="519">the same as in Figure 2(a). In addition, we present the state-by-state intensity</text>
<text font="1" height="13" left="202" textpieces="0" top="461" width="519">maps in the middle column of Figure 3 by aggregating f spatially. The Socio-</text>
<text font="1" height="13" left="202" textpieces="0" top="479" width="519">scope results match the range maps well for all animals. The right column in</text>
<text font="1" height="13" left="202" textpieces="0" top="497" width="519">Figure 3 shows the daily animal activities by aggregating f temporally. These</text>
<text font="1" height="13" left="202" textpieces="0" top="515" width="346">curves match the animals&#8217; diurnal patterns well, too.</text>
<text font="1" height="13" left="225" textpieces="0" top="533" width="496">The Socioscope estimates are superior to the baseline methods in Table 1.</text>
<text font="1" height="13" left="202" textpieces="0" top="551" width="519">Due to space limit we only present two examples on chipmunks, but note that</text>
<text font="1" height="13" left="202" textpieces="0" top="569" width="519">similar observations exist for all animals. The baseline estimator of simply scal-</text>
<text font="1" height="13" left="202" textpieces="2" top="587" width="519">ing x(1)+ x(2) produced the temporal and spatial aggregates in Figure 5(a,b).</text>
<text font="1" height="13" left="202" textpieces="0" top="605" width="519">Compared to Figure 3(b, right), the temporal curve has a spurious peak around</text>
<text font="1" height="13" left="202" textpieces="0" top="622" width="519">4-5pm. The spatial map contains spurious intensity in California and Texas,</text>
<text font="1" height="13" left="202" textpieces="0" top="640" width="519">states outside the chipmunk range as shown in Figure 3(b, left). Both are pro-</text>
<text font="1" height="13" left="202" textpieces="0" top="658" width="519">duced by population bias when and where there were strong background social</text>
<text font="1" height="13" left="202" textpieces="0" top="676" width="519">media activities (see Figure 2(b,c)). In addition, the spatial map contains 27</text>
<text font="1" height="13" left="202" textpieces="0" top="694" width="519">&#8220;holes&#8221; (states with zero intensity, colored in blue) due to data scarcity. In con-</text>
<text font="1" height="13" left="202" textpieces="0" top="712" width="519">trast, Socioscope&#8217;s estimates in Figure 3 avoid this problem by regularization.</text>
<text font="1" height="13" left="202" textpieces="2" top="730" width="519">Another baseline estimator (x(1)+ x(2))/z(1) is shown in Figure 5(c). Although</text>
<text font="1" height="13" left="202" textpieces="0" top="748" width="519">corrected for population bias, this estimator lacks the transition model and reg-</text>
<text font="1" height="13" left="202" textpieces="0" top="766" width="339">ularization. It does not address data scarcity either.</text>
<text font="5" height="16" left="202" textpieces="1" top="808" width="144">6  Future Work</text>
<text font="1" height="13" left="202" textpieces="0" top="842" width="519">Using social media as a data source for spatio-temporal signal recovery is an</text>
<text font="1" height="13" left="202" textpieces="0" top="860" width="519">emerging area. Socioscope represents a &#64257;rst step toward this goal. There are</text>
<text font="1" height="13" left="202" textpieces="0" top="878" width="141">many open questions:</text>
<text font="1" height="13" left="225" textpieces="0" top="896" width="496">1. We treated target posts as certain. In reality, a natural language processing</text>
<text font="1" height="13" left="202" textpieces="0" top="914" width="519">system can often supply a con&#64257;dence. For example, a tweet might be deemed to</text>
<text font="1" height="13" left="202" textpieces="0" top="932" width="519">be a target post only with probability 0.8. It will be interesting to study ways</text>
<text font="1" height="13" left="202" textpieces="0" top="950" width="333">to incorporate such con&#64257;dence into our framework.</text>
<text font="1" height="13" left="225" textpieces="0" top="968" width="496">2. The temporal delay and spatial displacement between the target event and</text>
<text font="1" height="13" left="202" textpieces="0" top="986" width="519">the generation of a post is commonplace, as discussed in footnote 2. Estimating</text>
<text font="4" height="12" left="202" textpieces="1" top="142" width="328">14      Xu, J., Bhargava, A., Nowak, R., and Zhu, X.</text>
<text font="4" height="12" left="346" textpieces="0" top="311" width="231">(a) armadillo (Dasypus novemcinctus)</text>
<text font="4" height="12" left="366" textpieces="0" top="449" width="191">(b) chipmunk (Tamias striatus)</text>
<text font="4" height="12" left="305" textpieces="0" top="588" width="314">(c) squirrel (Sciurus carolinensis and several others)</text>
<text font="4" height="12" left="356" textpieces="0" top="726" width="212">(d) opossum (Didelphis virginiana)</text>
<text font="4" height="12" left="202" textpieces="0" top="757" width="519">Fig. 3. Socioscope estimates match animal habits well. (Left) range map from Nature-</text>
<text font="4" height="12" left="202" textpieces="2" top="775" width="505">Serve, (Middle) Socioscope b f aggregated spatially, (Right) b f aggregated temporally.</text>
<text font="4" height="12" left="339" textpieces="3" top="937" width="250">(a) x(1)+ x(2)            (b) Socioscope b f</text>
<text font="4" height="12" left="305" textpieces="1" top="972" width="313">Fig. 4. Raw counts and Socioscope b f for chipmunks</text>
<text font="4" height="12" left="282" textpieces="1" top="142" width="439">Socioscope: Spatio-Temporal Signal Recovery from Social Media      15</text>
<text font="4" height="12" left="259" textpieces="6" top="300" width="424">(a) x(1)+ x(2)             (b) x(1)+ x(2)          (c) (x(1)+ x(2))/z(1)</text>
<text font="4" height="12" left="202" textpieces="0" top="331" width="519">Fig. 5. Examples of inferior baseline estimators. In all plots, states with zero counts</text>
<text font="4" height="12" left="202" textpieces="0" top="347" width="116">are colored in blue.</text>
<text font="1" height="13" left="202" textpieces="0" top="396" width="519">an appropriate transition matrix P from social media data so that Socioscope</text>
<text font="1" height="13" left="202" textpieces="0" top="414" width="411">can handle such &#8220;point spread functions&#8221; remains future work.</text>
<text font="1" height="13" left="225" textpieces="0" top="433" width="496">3. It might be necessary to include psychology factors to better model the</text>
<text font="1" height="13" left="202" textpieces="0" top="450" width="519">human &#8220;sensors.&#8221; For instance, a person may not bother to tweet about a chip-</text>
<text font="1" height="13" left="202" textpieces="0" top="468" width="470">munk roadkill, but may be eager to do so upon seeing a moose roadkill.</text>
<text font="1" height="13" left="225" textpieces="0" top="487" width="496">4. Instead of discretizing space and time into bins, one may adopt a spatial</text>
<text font="1" height="13" left="202" textpieces="0" top="505" width="477">point process model to learn a continuous intensity function instead [13].</text>
<text font="1" height="13" left="225" textpieces="0" top="523" width="422">Addressing these considerations will further improve Socioscope.</text>
<text font="5" height="16" left="202" textpieces="0" top="572" width="158">Acknowledgments</text>
<text font="1" height="13" left="202" textpieces="0" top="612" width="519">We thank Megan K. Hines from Wildlife Data Integration Network for providing</text>
<text font="1" height="13" left="202" textpieces="0" top="630" width="519">range maps and guidance on wildlife. This work is supported in part by the</text>
<text font="1" height="13" left="202" textpieces="0" top="648" width="421">Global Health Institute at the University of Wisconsin-Madison.</text>
<text font="5" height="16" left="202" textpieces="0" top="697" width="94">References</text>
<text font="4" height="12" left="209" textpieces="0" top="737" width="512">1. Allan, J.: Topic Detection and Tracking: Event-Based Information Organization.</text>
<text font="4" height="12" left="227" textpieces="0" top="753" width="303">Kluwer Academic Publishers, Norwell, MA (2002)</text>
<text font="4" height="12" left="209" textpieces="0" top="770" width="512">2. Becker, H., Mor, N., Gravano, L.: Beyond trending topics: Real-world event iden-</text>
<text font="4" height="12" left="227" textpieces="0" top="787" width="494">ti&#64257;cation on twitter. In: Proceedings of the 15th International AAAI Conference</text>
<text font="4" height="12" left="227" textpieces="0" top="803" width="302">on Weblogs and Social Media. pp. 438&#8211;441 (2011)</text>
<text font="4" height="12" left="209" textpieces="0" top="820" width="512">3. Blei, D.M., Ng, A.Y., Jordan, M.I.: Latent dirichlet allocation. The Journal of</text>
<text font="4" height="12" left="227" textpieces="0" top="836" width="285">Machine Learning Research 3, 993&#8211;1022 (2003)</text>
<text font="4" height="12" left="209" textpieces="0" top="853" width="512">4. Cataldi, M., Di Caro, L., Schifanella, C.: Emerging topic detection on twitter based</text>
<text font="4" height="12" left="227" textpieces="0" top="870" width="494">on temporal and social terms evaluation. In: Proceedings of the 10th International</text>
<text font="4" height="12" left="227" textpieces="0" top="886" width="360">Workshop on Multimedia Data Mining. pp. 4:1&#8211;4:10 (2010)</text>
<text font="4" height="12" left="209" textpieces="0" top="903" width="512">5. Chung, F.R.K.: Spectral graph theory. Regional Conference Series in Mathematics,</text>
<text font="4" height="12" left="227" textpieces="0" top="920" width="334">American Mathematical Society, Providence, RI (1997)</text>
<text font="4" height="12" left="209" textpieces="0" top="937" width="512">6. Cornec, M.: Concentration inequalities of the cross-validation estimate for stable</text>
<text font="4" height="12" left="227" textpieces="0" top="953" width="301">predictors. Arxiv preprint arXiv:1011.5133 (2010)</text>
<text font="4" height="12" left="209" textpieces="0" top="970" width="512">7. Donoho, D., Johnstone, I., Kerkyacharian, G., Picard, D.: Density estimation by</text>
<text font="4" height="12" left="227" textpieces="0" top="987" width="397">wavelet thresholding. The Annals of Statistics 24, 508&#8211;539 (1996)</text>
<text font="4" height="12" left="202" textpieces="1" top="142" width="328">16      Xu, J., Bhargava, A., Nowak, R., and Zhu, X.</text>
<text font="4" height="12" left="209" textpieces="0" top="181" width="512">8. Earle, P., Guy, M., Buckmaster, R., Ostrum, C., Horvath, S., Vaughan, A.: OMG</text>
<text font="4" height="12" left="227" textpieces="0" top="197" width="494">earthquake! Can Twitter improve earthquake response? Seismological Research</text>
<text font="4" height="12" left="227" textpieces="0" top="214" width="178">Letters 81(2), 246&#8211;251 (2010)</text>
<text font="4" height="12" left="209" textpieces="0" top="230" width="512">9. Eisenstein, J., O&#8217;Connor, B., Smith, N.A., Xing, E.P.: A latent variable model for</text>
<text font="4" height="12" left="227" textpieces="0" top="247" width="494">geographic lexical variation. In: Proceedings of the 2010 Conference on Empirical</text>
<text font="4" height="12" left="227" textpieces="0" top="263" width="388">Methods in Natural Language Processing. pp. 1277&#8211;1287 (2010)</text>
<text font="4" height="12" left="202" textpieces="0" top="279" width="519">10. Gupte, M., Shankar, P., Li, J., Muthukrishnan, S., Iftode, L.: Finding hierarchy in</text>
<text font="4" height="12" left="227" textpieces="0" top="296" width="494">directed online social networks. In: Proceedings of the 20th International Confer-</text>
<text font="4" height="12" left="227" textpieces="0" top="312" width="278">ence on World Wide Web. pp. 557&#8211;566 (2011)</text>
<text font="4" height="12" left="202" textpieces="0" top="329" width="519">11. Lazer, D., Pentland, A.S., Adamic, L., Aral, S., Barabasi, A.L., Brewer, D., Chris-</text>
<text font="4" height="12" left="227" textpieces="0" top="345" width="494">takis, N., Contractor, N., Fowler, J., Gutmann, M., Jebara, T., King, G., Macy,</text>
<text font="4" height="12" left="227" textpieces="0" top="362" width="494">M., Roy, D., Alstyne, M.V.: Life in the network: the coming age of computational</text>
<text font="4" height="12" left="227" textpieces="0" top="378" width="295">social science. Science 323(5915), 721&#8211;723 (2009)</text>
<text font="4" height="12" left="202" textpieces="0" top="395" width="519">12. Mei, Q., Liu, C., Su, H., Zhai, C.: A probabilistic approach to spatiotemporal theme</text>
<text font="4" height="12" left="227" textpieces="0" top="411" width="494">pattern mining on weblogs. In: Proceedings of the 15th International Conference</text>
<text font="4" height="12" left="227" textpieces="0" top="427" width="248">on World Wide Web. pp. 533&#8211;542 (2006)</text>
<text font="4" height="12" left="202" textpieces="0" top="444" width="519">13. M&#248;ller, J., Waagepetersen, R.: Statistical inference and simulation for spatial</text>
<text font="4" height="12" left="227" textpieces="0" top="460" width="494">point processes. Monographs on statistics and applied probability, Chapman &amp;</text>
<text font="4" height="12" left="227" textpieces="0" top="477" width="211">Hall/CRC, Boca Raton, FL (2004)</text>
<text font="4" height="12" left="202" textpieces="0" top="493" width="519">14. Nocedal, J., Wright, S.: Numerical optimization. Springer series in operations re-</text>
<text font="4" height="12" left="227" textpieces="0" top="510" width="237">search, Springer, New York, NY (1999)</text>
<text font="4" height="12" left="202" textpieces="0" top="526" width="519">15. Patterson, B.D., Ceballos, G., Sechrest, W., Tognelli, M.F., Brooks, T., Luna, L.,</text>
<text font="4" height="12" left="227" textpieces="0" top="543" width="494">Ortega, P., Salazar, I., Young, B.E.: Digital distribution maps of the mammals</text>
<text font="4" height="12" left="227" textpieces="0" top="559" width="494">of the western hemisphere, version 3.0. Tech. rep., NatureServe, Arlington, VA</text>
<text font="4" height="12" left="227" textpieces="0" top="575" width="237">(2007), http://www.natureserve.org/</text>
<text font="4" height="12" left="202" textpieces="0" top="592" width="519">16. Sakaki, T., Okazaki, M., Matsuo, Y.: Earthquake shakes twitter users: real-time</text>
<text font="4" height="12" left="227" textpieces="0" top="608" width="494">event detection by social sensors. In: Proceedings of the 19th International Con-</text>
<text font="4" height="12" left="227" textpieces="0" top="625" width="368">ference on World Wide Web. pp. 851&#8211;860. WWW &#8217;10 (2010)</text>
<text font="4" height="12" left="202" textpieces="0" top="641" width="519">17. Settles, B.: Closing the Loop: Fast, Interactive Semi-Supervised Annotation With</text>
<text font="4" height="12" left="227" textpieces="0" top="658" width="494">Queries on Features and Instances. In: Proceedings of the Conference on Empirical</text>
<text font="4" height="12" left="227" textpieces="0" top="674" width="489">Methods in Natural Language Processing. pp. 1467&#8211;1478. Edinburgh, UK (2011)</text>
<text font="4" height="12" left="202" textpieces="0" top="690" width="519">18. Van Der Laan, M., Dudoit, S.: Uni&#64257;ed cross-validation methodology for selection</text>
<text font="4" height="12" left="227" textpieces="0" top="707" width="494">among estimators and a general cross-validated adaptive epsilon-net estimator:</text>
<text font="4" height="12" left="227" textpieces="0" top="723" width="494">Finite sample oracle inequalities and examples. U.C. Berkeley Division of Bio-</text>
<text font="4" height="12" left="227" textpieces="0" top="740" width="308">statistics Working Paper Series pp. 130&#8211;236 (2003)</text>
<text font="4" height="12" left="202" textpieces="0" top="756" width="519">19. Vardi, Y., Shepp, L.A., Kaufman, L.: A statistical model for positron emission</text>
<text font="4" height="12" left="227" textpieces="0" top="773" width="494">tomography. Journal of the American Statistical Association 80(389), 8&#8211;37 (1985)</text>
<text font="4" height="12" left="202" textpieces="0" top="789" width="519">20. Willett, R., Nowak, R.: Multiscale poisson intensity and density estimation. IEEE</text>
<text font="4" height="12" left="227" textpieces="0" top="806" width="370">Transactions on Information Theory 53(9), 3171&#8211;3187 (2007)</text>
<text font="4" height="12" left="202" textpieces="0" top="822" width="519">21. Yang, Y., Pierce, T., Carbonell, J.: A study of retrospective and on-line event</text>
<text font="4" height="12" left="227" textpieces="0" top="838" width="494">detection. In: Proceedings of the 21st Annual International ACM SIGIR Conference</text>
<text font="4" height="12" left="227" textpieces="0" top="855" width="444">on Research and Development in Information Retrieval. pp. 28&#8211;36 (1998)</text>
<text font="4" height="12" left="202" textpieces="0" top="871" width="519">22. Yin, Z., Cao, L., Han, J., Zhai, C., Huang, T.: Geographical topic discovery and</text>
<text font="4" height="12" left="227" textpieces="0" top="888" width="494">comparison. In: Proceedings of the 20th International Conference on World Wide</text>
<text font="4" height="12" left="227" textpieces="0" top="904" width="151">Web. pp. 247&#8211;256 (2011)</text>
