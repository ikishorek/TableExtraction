Iteration 0 Learning Rate 0.2 Total Error = 10922.0 Sparse Error = 86.0
Iteration 1 Learning Rate 0.196039734661 Total Error = 593.0 Sparse Error = 593.0
Iteration 2 Learning Rate 0.19215788783 Total Error = 593.0 Sparse Error = 593.0
Iteration 3 Learning Rate 0.188352906717 Total Error = 593.0 Sparse Error = 593.0
Iteration 4 Learning Rate 0.184623269277 Total Error = 593.0 Sparse Error = 593.0
Iteration 5 Learning Rate 0.180967483607 Total Error = 593.0 Sparse Error = 593.0
Iteration 6 Learning Rate 0.177384087343 Total Error = 593.0 Sparse Error = 593.0
Iteration 7 Learning Rate 0.17387164708 Total Error = 593.0 Sparse Error = 593.0
Iteration 8 Learning Rate 0.170428757793 Total Error = 593.0 Sparse Error = 593.0
Iteration 9 Learning Rate 0.167054042282 Total Error = 593.0 Sparse Error = 593.0
Iteration 10 Learning Rate 0.163746150616 Total Error = 593.0 Sparse Error = 593.0
Iteration 11 Learning Rate 0.160503759592 Total Error = 595.0 Sparse Error = 593.0
Iteration 12 Learning Rate 0.157325572213 Total Error = 596.0 Sparse Error = 593.0
Iteration 13 Learning Rate 0.154210317161 Total Error = 596.0 Sparse Error = 593.0
Iteration 14 Learning Rate 0.151156748291 Total Error = 591.0 Sparse Error = 577.0
Iteration 15 Learning Rate 0.148163644136 Total Error = 609.0 Sparse Error = 572.0
Iteration 16 Learning Rate 0.145229807415 Total Error = 469.0 Sparse Error = 399.0
Iteration 17 Learning Rate 0.142354064553 Total Error = 419.0 Sparse Error = 319.0
Iteration 18 Learning Rate 0.139535265214 Total Error = 400.0 Sparse Error = 296.0
Iteration 19 Learning Rate 0.136772281842 Total Error = 411.0 Sparse Error = 253.0
Iteration 20 Learning Rate 0.134064009207 Total Error = 410.0 Sparse Error = 243.0
Iteration 21 Learning Rate 0.131409363963 Total Error = 407.0 Sparse Error = 235.0
Iteration 22 Learning Rate 0.128807284217 Total Error = 405.0 Sparse Error = 231.0
Iteration 23 Learning Rate 0.126256729101 Total Error = 406.0 Sparse Error = 229.0
Iteration 24 Learning Rate 0.123756678361 Total Error = 399.0 Sparse Error = 215.0
Iteration 25 Learning Rate 0.121306131943 Total Error = 400.0 Sparse Error = 212.0
Iteration 26 Learning Rate 0.118904109594 Total Error = 396.0 Sparse Error = 208.0
Iteration 27 Learning Rate 0.116549650475 Total Error = 386.0 Sparse Error = 196.0
Iteration 28 Learning Rate 0.11424181277 Total Error = 386.0 Sparse Error = 196.0
Iteration 29 Learning Rate 0.111979673313 Total Error = 386.0 Sparse Error = 194.0
Iteration 30 Learning Rate 0.109762327219 Total Error = 389.0 Sparse Error = 194.0
Iteration 31 Learning Rate 0.107588887519 Total Error = 386.0 Sparse Error = 191.0
Iteration 32 Learning Rate 0.105458484809 Total Error = 376.0 Sparse Error = 185.0
Iteration 33 Learning Rate 0.103370266898 Total Error = 362.0 Sparse Error = 182.0
Iteration 34 Learning Rate 0.101323398473 Total Error = 360.0 Sparse Error = 178.0
Iteration 35 Learning Rate 0.0993170607583 Total Error = 358.0 Sparse Error = 176.0
Iteration 36 Learning Rate 0.097350451192 Total Error = 354.0 Sparse Error = 173.0
Iteration 37 Learning Rate 0.0954227831042 Total Error = 359.0 Sparse Error = 172.0
Iteration 38 Learning Rate 0.093533285402 Total Error = 340.0 Sparse Error = 174.0
Iteration 39 Learning Rate 0.091681202261 Total Error = 344.0 Sparse Error = 174.0
Iteration 40 Learning Rate 0.0898657928234 Total Error = 347.0 Sparse Error = 174.0
Iteration 41 Learning Rate 0.0880863309012 Total Error = 349.0 Sparse Error = 173.0
Iteration 42 Learning Rate 0.0863421046858 Total Error = 348.0 Sparse Error = 171.0
Iteration 43 Learning Rate 0.0846324164635 Total Error = 349.0 Sparse Error = 170.0
Iteration 44 Learning Rate 0.0829565823363 Total Error = 337.0 Sparse Error = 167.0
Iteration 45 Learning Rate 0.0813139319481 Total Error = 322.0 Sparse Error = 147.0
Iteration 46 Learning Rate 0.0797038082169 Total Error = 320.0 Sparse Error = 146.0
Iteration 47 Learning Rate 0.0781255670717 Total Error = 324.0 Sparse Error = 147.0
Iteration 48 Learning Rate 0.076578577195 Total Error = 322.0 Sparse Error = 148.0
Iteration 49 Learning Rate 0.0750622197703 Total Error = 321.0 Sparse Error = 147.0
#components           1     5341      489       1
Tuffy       6   13     40     106
Tuffy-p    0.11M  0.39M  0.17M  7.9K
Tuffy-p RAM      9 MB     8 MB   19 MB  184 MB
Tuffy cost     2534  1635    1281    18717
Fixed join algorithm   112   306   >36,000   >16,000
Tuy+parallelism    28    42
Single-column tables      96%         94.8%       94.5%      99.8%
Memory                 3x 4GB DDR3
Memory                 8x 2GB DDR2
L2-R   Radix / 2048     Radix / 2048
probe     6,152      36     54,761        1        0
probe     8,052      13     54,761        1        0
Uniform
L2-R     14.46        12.71          1.14X
High skew
L2-R     15.04        13.61          1.11X
Uniform
L2-R     46.62        18.88          2.47X
High skew
L2-R     66.01        43.16          1.53X
Sun UltraSPARC T2   29%  21%   20%    23%
L2-R     5.82 (0.46X)  12.71 (1.00X)       DNF
2        Document title, author, aliation, abstract  Page 1,
in a xed order.
3        Figure caption, table caption, table body, footnote, Ref-
6         Figure captions are beneath the gure;  table captions
are above the table.
7        Table captions start with keywords Table or TABLE
while Figure captions start with Figure or FIGURE.
tb2      w1,2,1         ...         wx,2,1    w1,2,2          ...         wy,2,2    ...    w1,2,k          ...          wz,2,k      ...        ...
.
.
.          ...
.
.
.             ...         ...
.
.
.             ...
.
.
.       ...
.
.
.             ...        ...        ...
IT T F       ...            ...            ...                        ...            ...      ...      ...            ...            ...        ...        ...
Computer Science         50         68
Table Reference text             100.00         100.00
Ranking        The Method to set-up
the test-bed
Accuracy (%)
TableSeer       Both methods                 69.61
All factors            69.61
TTFITTF, MW         58.05         9.56
(v) Socioscope with x(1), x(2)           0.16
(vi) Socioscope with x(1), x(2), x(3) 0.12
O    1    1    37     3   0
SVM        0.85       0.42     0.31   0.36
N   0    78    4    41    16   9306
Not       26   559
DV-            0     11         0       9
*** p < 0.001  ** p < 0.01  * p < 0.05  . p < 0.1
predicted as
ang.  emb.  emp.  fear  pri.   rel.   sad.
sad.       4      0      2    14     0     4    82
0.15            0.31    0.43      0.42
k   :  # paths parameter in k-MAP, Staccato
m  :  # chunks in Staccato (1  m  l)
Dataset
DB Papers (DB)     16       627    359MB  54kB
N umAns            # Answers queried for
Query     MAP     k-MAP    FullSFA   Staccato
DB2    0.96/0.76  0.96/0.76  0.33/1.00    0.91/0.97
DB2      0.07        0.33      619.31        0.86
Approach     Table Name
Attributes
Primary Key
Name            Type
DataKey        INTEGER
DataKey, ChunkNum,
Data            TEXT
Dataset  S.No.         Query         # in Truth
7       spontan(\x)          99
Query
LT7    0.84/0.88  0.83/0.88  0.83/0.88    0.83/0.88
Query
LT7    0.15     1.00     887.19       4.23
DBLP          600M          2.3M       7.2G
PostgreSQL                                 DBMS A                           DBMS B (8 segments)
Dataset
(0.25s)                                      (35.4s)                                     (0.16s)
PostgreSQL                                 DBMS A                           DBMS B (8 segments)
Dataset
(0.29s)                                      (5.1s)                                      (0.1s)
PostgreSQL   (Native)   (Native)  (In-mem.)
LR
N/A       N/A         X
T heDisT oN extLine            Vertical gap to the next line
P                                  Denition
      the vertical distance between two top Y-axis values:
alpha = Yi+1 Yi
    the vertical distance between two bottom Y-axis values:
      the horizontal distance between these two characters:
               the maximum vertical distance between
two characters in a same line
Precision of sparse line detection    98.60    99.22    98.79
CRF, Orthographic+Lexical+Layout, A     98.76%    96.20%
Det in [16]                               < 70%
CPU       Intel X5550 2 sockets    SysPower   130.03C0.2369
C = CPU utilization
Laptop B                 i7 620m (2/4)    8GB   11W (screen off)
RBbld Rate at which a Beefy node builds its hash table (MB/s)
UW bld Wimpy node CPU bandwidth during the build phase
UBbld Beefy node CPU bandwidth during the build phase
RW prb Rate at which the Wimpy node probes its hash table (MB/s)
RBprb Rate at which the Beefy node probes its hash table (MB/s)
UW prb Wimpy node CPU bandwidth during the probe phase
UBprb Beefy node CPU bandwidth during the probe phase
CB= 5037 Maximum CPU bandwidth of a Beefy node (MB/s)
CW = 1129 Maximum CPU bandwidth of a Wimpy node (MB/s)
GB = 0.25 Beefy CPU utilization constants for P-store
GW = 0.13 Wimpy CPU utilization constants for P-store
fB(c) = 130.03  (100c)0.2369 (c=CPU util.) Beefy node power model
H = MW  (Bld  Bldsel)/(NB + NW) Wimpy can build the hash table
Simple                     54 (40%)     44 (36.7%) 
           Header column     139      126 
Type      Learning model     Precision   Recall    F 
Random forest       0.982       0.982     0.982 
Together                 0.974        0.978      0.976 
             Baseline    Heuristic   RF 
Fake         0.011       0.011       0.007 
zone      The area of a slotted page where all instances
of a group are written
zone-record   An instance of the attributes in a particular
group
|P |       The number of all unique partitions
Group                                Cost
{priority}                        0.125
{priority,usage}                0.25
usage}                0.125
{priority,
location,usage}   0.375
{{priority,location,usage}}        0.375
Q1   SELECT [varies] FROM Tenk1   Non-clustered
Q2   SELECT [varies] FROM Tenk1   Sequential
WHEREunique1<200, 000 le scan
[1.6047252525815203, 3.1051965360552214, 0.18898028640010126, 5.162490903198029, 0.5416428575993655, -0.24856801295820802, 0.18184466690873824, 1.3735521965210247, 2.7488654722500665, 5.005814600680659, 5.577517872335907, 3.516487678061795, 1.1999840319705075, 4.316534582156025]
