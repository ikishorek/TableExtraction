Table Extraction from pdf files
Abstract	????????????????????? ================= [very important. Be precise]
1 Introduction	?????????????????????
[============================== 
Points: 
Introduction (Ideas)
Why we chose this problem?
	Error Analysis done on an existing IE system (GDD) showed us that there will be 5.6% improvement in PR.
Why concentrating on pdf documents?
	papers are published mostly as pdf docs.
What does experimental results show you?
How the remaining of the paper is organised?
No publicly available data set makes this problem harder. 
No Open source working software.
==============================]

2 Related Work
2.1 Related works on Table Detection:
Table Detection approaches can mainly be classified into (1) Predefined structure based (2) Heuristics based and (3) Statistical and ML based. 

Pinto et al. [2] work on the table detection problem from HTML documents from a particular website (ie for a particular domain). They have used a CRF for table detection where they label all the lines in a document into a predefined set of labels. They use these labelled lines to detect the presense of a table and report a F1 of 92% on locating the table. However, their feature set relies heavily on the structure of tables and is domain dependent. They expect dashed lines and white space markers to be delineate table rows and data which is never the case in our training set. 

Yildiz et al.[1] base their work primarily on heuristics to locate a table in pdf documents. They use the output of pdftohtml* to do preprocessing and table detection. No sophisticated algorithms are used in either the preprocessing and table detection phase and hence their recall is as low as 84%.

Liu et al.[3] build a search engine for tables called TableSeer. They design a novel heuristics based method for table detection called the page box-cutting method to segment a page into different boxes where each box has a high cohesion but low coupling with other boxes. Nevertheless, Liu et al. work primarily on scientific pdf documents and make a lot of assumptions that do not work well in other cases. Eg: They assume that the table caption is always on the top of the table and there is a fixed font size for all table information. Given these assumptions they get a recall of 93.5% and a precision of 100%.

Liu et al.[4] work exclusively on the table detection problem from pdf documents. They make use of the property that in most pdf documents, the table lines are sparse. They train a CRF and a linear SVM to detect tables and report a F-measure of 96.36% for CRF and 94.38% for linear SVM. Our work on table detection is also primarily based on this paper. However, we differ from [4] in that (1) We pose the problem as a classification problem where we classify each line as either SPARSE or NONSPARSE, whereas [4] posed it as a sequence labeling problem to label each line into either NONSPARSE or one of a several kind of SPARSE lines. (2) Also, our work involves a more sophisticated feature set and complex pre and post processing algorithms than described in [4]. (3) And we empirically compare the performance of CRF and a SVM with a Gaussian kernel (of degree 5) instead of a linear SVM as done in [4].

*pdftohtml [http://pdftohtml.sourceforge.net]

2.2 Related works on Table Decomposition: ?????????????????????
	[My 2 cents] [2] relies on dashed markers and white space for separation between header and data rows

3 Machine Learning Background for Conditional Random Fields (CRF):
Conditional Random Fields (CRF) are undirected graphical models primarily used for sequence labeling. CRF - HMM form a discriminative - generative pair of graphical models. CRF models the posterior probability of predicting a label sequence given an input sequence. 

The posterior probability is given by
P (O|I) = (1/Z) exp( (i =1..n)(j=1..m) Lj fj (Oi−1 , Oi , I, i))
O -> Output (label) sequence
I -> Input sequence
Lj -> weight of the feature
fj -> feature given previous state, current state, Input sequence and i
Z -> Normalisation factor (sum over all possible output label sequences)

(i = 1..n) fj  (Oi−1 , Oi , I, i) => Fj (I, O) (feature function)

Inference is done by a variation of the vitterbi algorithm as specified in [5].
Training is to done by setting the weights to maximize the conditional log likelihood of labeled sequences in the training set D. The algorithms and techniques to update the weights is specified in [5]

4 Architecture of Table Extractor: [A diagramatic representation]
Fig 1 shows the architecture of our table extraction system. As can be inferred from Fig 1, our table extraction system is primarily divided into 2 major components: Table Detection and Table Decomposition. The Table Detection component detects the boundaries of the tables in the pdf documents and passes the detected tables to the Table Decomposition component. The Table Decomposition component processes the detected tables and identifies header rows/columns and data rows. We describe each component in detail in the following sections.

5 Table Detection:
	Liu et al.[4] observed that in most of the pdf documents, table lines followed a particular structure and are sparse. According to them, a line is sparse if the minimum space gap between pair of consecutive words is larger than a threshold (or) length of the line is much shorter than a threshold. We too observed the same behavior in the documents we examined and hence as proposed in [4], we use this sparse line property of table lines for table detection. In [4], the problem was posed as a sequence labeling problem where they labeled each line as either NONSPARSE or one of the different kind of SPARSE lines. We however, pose the problem as a classic classification problem where each line is classified as either a candidate TABLE or NONTABLE line. 
We now explain the different modules in the table detection component.

1. Pre-Processing:
	We use pdftohtml [5] for converting the input pdf document to a xml file. The xml output of pdftohtml [5] consists of a set of page tags with each page tag consisting of a set of text tags and fontspec tags. The text tags consists of attributes like top, left, width, height and font. The fontspec tag consists of attributes like id, size, family and color. However, pdftohtml does not convert image based tables. It also does not handle correctly column information (ie there is no column tags) or subscript/superscript information. In these cases, it splits the same sentence into multiple text tags and order of the text tags is not maintained. To overcome these limitations of [5], we had to do preprocess the xml documents based on certain heuristics. The pseudocode of our preprocessing algorithm is as follows:

		ALGORITHM 1
	for each pagetag in xml file:
		combinesubscripts and superscripts based on top/height and left/width merge information
		combine text pieces based on top information[Add 'textpieces' attribute for each texttag in xml]
		find columns in page based on sharp difference in height between previous and current tag

The result of the preprocessing stage is a list of all page tags each containing a list of all preprocessed text tags (each containing an extra 'textpieces' attribute)

2. Feature Sets:
	We used a wide variety of featuers as suggested in [4]. However, we also introduced some new features by inspecting the structure of different tables in pdf documents. The features can be broadly divided into orthographic, lexical, layout and other features. We used the same feature set to train different classifiers like CRF, SVM and Logistic Regressor for our experiments, except that only CRF had the previous and current tag information for each feature. We used forward selection on a set of features and selected those features that provided us better classification accuracy. We describe each feature in detail below.

Orthographic Features:
1. Font Size - Same font size between previous and current line.
2. Begins With Captial Letter - First word begins with a capital letter in current line.

Lexical Features:
1. Keyword Presence - Presence of 'Table' keyword followed by a number Eg: Table 1, Table 3.2

Layout Features:
1. Textpieces - Using the 'textpieces' attribute added in the proprocessing stage to check if it is greater than a threshold
2. No. of words in line - If it is equal to 1. [This feature was useful because pdftohtml [5] created a separate text tag with only one word for certain table lines]
3. Height Difference (Previous) - Difference in height between previous line and current line 
4. Height Difference (Next) - Difference in height between next line and current line
5. Largest Space - If the largest space between any pair of consecutive words in the current line is greater than a threshold.
6. Same Space - If the largest space is equal to the smallest space between any pair of consecutive words in the current line.
7. No. of words in line -  If it is greater than a threshold.
8. No. of words with the largest space difference - If the number of the words with largest space difference (Layout Feature (5)) is greater than a threshold.

Other Features (Only for CRF):
1. Previous and current tag are TABLELINE
2. Previous and current tag are NONTABLELINE

3. Machine Learning Techniques:
Conditional Random Field (CRF):
	We implemented CRF using the algorithm specified by Charles Elkan in [6]. For the weight learning we use Stochastic Gradient Descent with the weight update rule specified by the Collins Perceptron. However, we use weights averaged over a epoch instead of actual weights to prevent the magnitude of the weights from getting a value too high. 

The weight update rule is as follows:
	wj := wj + λ(Fj (x, y) − Fj (x, y'))/N
	wj -> weight of feature j
	λ -> Learning rate 
	Fj (x, y) -> (Actual) Feature function for that feature j for label y
	Fj (x, y') -> (Predicted) Feature function for that feature j for label y'
	N -> Total number of training instances

We also used a decayed learning rate for quicker convergence of weight learning. The decaying function is given by
	LearningRate (at a particular epoch) = StartLearningRate * exp(-Epochcount/TotalNumberofEpochs);

Support Vector Machine (SVM):
	The PyML [7] library was used for SVMs. For this classification problem, we used an SVM with a Gaussian Kernel of degree 5 with a C value of 20.
The hyperparameters were chosen by trial and error and even this seemed to give us a better classification accuracy. In future work, we plan to do a more formal search of the hyperparameters using Grid Search.

Logistic Regressor (LR):
	We implemented a LR modeling it as a single layer neural network with sigmoid output using Stochastic gradient descent. Decayed learning rate was used for training. The sigmoid was thresholded to 0.5 for prediction. Anything above 0.5 is predicted as TABLELINE.

4. Post Processing:
	After the classifier identifies the candidate TABLELINEs, we postprocess it so that we can remove false positives and include those lines which are false negatives (ie lines which were TABLELINE but were classified as NONTABLELINE). We try to increase the recall of the table lines as much as possible as the NONTABLELINEs will however be removed (if irrelevant) in the table decomposition step. We adjust various thresholds with this premise in mind. The postprocessing algorithm is as follows:
	output = list()
	for all lines:
		if line begins with a keyword*
			data = FindPossibleTableStructureAfterThisLine(curindex)
			if data is not null:
				add table to output
				continue
		if line is TABLELINE
			data = FindPossibleTableStructureAfterThisLine(curindex)
			if data is not null:
				keywordloc = IsTableKeywordAfterThisLine(curindex)
				if keywordloc is not -1:
					data = FindPossibleTableStructureBeforeThisLine(curindex)
					if data is not null:
						add table to output
	return output

*As of now, we only use table followed by a number (Eg: 'Table 1', 'Table 3.2') as our keyword. We plan to add more keywords like 'Figure' in future work.

The subroutine FindPossibleTableStructureAfterThisLine is as follows:
	data = list()
	sparseline = find next sparse line after current line
	if difference between current line no and sparseline's line no > threshold1
		return
	append the lines between current line and next sparseline to data
	while (difference between current line no and next sparse line no < threshold2)
		append lines to data
	return data

The subroutine FindPossibleTableStructureBeforeThisLine is similar to the FindPossibleTableStructureAfterThisLine subroutine except that the scan is carried bottom-up instead of top-down.

6 Table Decomposition: ????????????????????????????

7 Experiments and Result analysis:
In this section, we demonstrate the experiments we ran for table detection and table decomposition and analyse the results.

7.1 Table Detection
As described in Section 4 in this paper, we posed the table detection problem as a classification problem where every line is classified as either a TABLELINE or NONTABLELINE. We trained models using 3 different Machine Learning techniques - CRF, SVM (Gaussian kernel, degree 5) and LR and evaluated their performance. 

7.1.1 Data Set:
One of the biggest challenges faced was that there was no off-the-shelf annotated data set available for this problem. So, we manually annotated our dataset. We took 15 pdf files taken at random from the publications page of CS faculty from the University of Wisconsin, Madison. Each pdf file was first converted to xml using pdftohtml. They were then passed through the preprocessing algorithm as described in Algorithm 1. Each xml preprocessed was converted to a HTML file which was hosted on a web server. The HTML file was designed in a way to allow the user to demarcate the table boundary. When the user clicked on the 'Submit' button on the page, a CGI script written in python read the HTML post data and wrote the annotated data to a file. Though, annotations for all these 15 pdfs were done by us, the main reason to create HTML files and publish them in a web server is two fold: (1)It is easy to annotate the training data on a web page for the format that is required by our system, (2) For annotating a large number of pdf documents (going forward), we can easily crowd source the effort. Crowd sourcing drastically reduces the time required to annotate data and is very cheap. There are, of course, many challenges associated with crowd sourcing and tackling them is beyond the scope of this paper. 

The 15 pdf files contained a total of 16052 lines out of which 14310 were NONTABLELINEs and 1742 lines were TABLELINEs. Also they contain 65 tables in total.

Empirical Evaluation of the different techniques:
Detection of TABLELINE:
We adopt a 5 fold Cross Validation approach to empirically compare the 3 different learning settings - CRF, SVM and LR. The confusion matrix (indicating the actual vs predicted classes) for the 3 methods - CRF, SVM and LR are listed in Tables 1, 2 and 3 respectively. Also, We can infer the precision and recall for both the classes (TABLELINE and NONTABLELINE) from the Confusion matrices.
Precision is defined as True Positives / (True Positives + False Positives)
Recall is defined as True Positives / (True Positives + False Negatives)
The precision and recall for the NONTABLELINE class are listed in Table 4. Table 5 contains the precision and recall for the TABLELINE class.

[======================= Replace NS with NONTABLELINE =======================
 and =================== S with TABLELINE========== also x axis is Actual and y axis is predicted =======================]
Table 1
CRF (with Initial Learning Rate 0.2 and running for 80 epochs)
	 NS    S   
    NS14156   154  
     S 1291   451 
Table 2
SVM (with a Gaussian Kernel of degree 5 and C = 20)
        NS    S   
    NS13809   501  
     S 821    921 
Table 3
LR (with Initial Learning Rate 0.2 and running for 50 epochs)
	 NS    S   
    NS14224   86  
     S 1216   526 

Table 4: Precision and Recall of NONTABLELINE
			Precision Recall (in percentage)
CRF			91.64      98.92
SVM Gaussian		94.39	   96.50
Logistic Regression	92.12	   99.40

Table 5: Precision and Recall of TABLELINE
			Precision Recall (in percentage)
CRF			74.55      25.89
SVM Gaussian		64.77	   52.87
Logistic Regression	85.95	   30.19


The reason for the very low precision and recall for the TABLELINE class are two fold: (1) Lack of a large number of TABLELINEs in our dataset. (2) Features engineered towards reducing the error of NONTABLELINEs instead of that of TABLELINEs. Nevertheless, if we add more training data with a lot of TABLELINEs and add in more features which are geared towards reducing the error rate of TABLELINEs, we are certain than the Precision and Recall of the TABLELINE class would improve.

Impact of PostProcessing:

Even though the precision and recall of TABLELINEs is very low, when combined with our postprocessing algorithm (explained in Section 5.4) for Table boundary detection, surprisingly most of the tables and their boundaries are properly detected. This can be explained by the following reasons (1) A low precision and recall for TABLELINE class means that some of the TABLELINEs are missed and are classified as NONTABLELINEs. However, the precision and recall of the NONTABLELINEs is very high. This means that not many NONTABLELINEs are classified as TABLELINEs. (2) Since our postprocessing algorithm tries to include those lines classified as NONTABLELINEs in between TABLELINEs (which seems to be the major scenario in our case), the actual TABLELINEs which were misclassified as NONTABLELINEs are added back to the result. The precision and recall of TABLELINE after postprocessing is given by Table 6.

Table 6: Precision and Recall of TABLELINE after postprocessing
			Precision Recall (in percentage)
CRF			79.10      33.46
SVM Gaussian		67.76	   60.44
Logistic Regression	88.49	   37.94

Our initial assumption from the works of Liu et al. [4] was that sequence labeling using CRF should perform better than any classifier. But surprisingly, in our experiments we found that SVM with a Gaussian Kernel gave better detection of table boundaries than CRF and LR. Eventhough the precision of SVM is lower, the recall is high relative to the other techniques which implies most of the TABLELINEs are retrieved after postprocessing leading to better table boundary detection. However, to conclusively say that SVM with a Gaussian Kernel is the best approach for this problem, we need to try out more experiments with carefully selected new features and varying the number of epochs and the learning rate of CRF and LR. We plan to do this as part of our future work.

7.2 Table Decomposition: ??????????????????????

8 Code Open Source: ????????????????
The implementation is open source and is located in GitHub (https://github.com/shriram-sridharan/TableExtraction). Please read the README.txt file for the dependencies and the procedure to execute the code. We greatly encourage and appreciate any feedback on the project. 

9 Conclusion:
In this project, we have built a prototype of a table extraction system. We empirically tested the table detection part on a sequence labeler and two classifiers and have shared our experimental results. [Insert for Table decomposition ???????????]We learnt that for this problem, a purely heuristic solution or a purely Machine Learning technique based solution perform poorly when compared with a hybrid approach involving both heuristics and Machine Learning (ML) techniques. Also, we learnt that feature selection and evaluation plays a vital role in the performance of a ML technique. Going forward, we plan to add in more features and evaluate the performance. We also plan to use Schema Matching techniques to identify the significance of the detected rows/columns so that the information in the data rows become more relevant in the context of an Information Extraction (IE) system. We plan to incorporate and test this with a real time IE system such as GeoDeepDive (http://hazy.cs.wisc.edu/hazy/geodeepdive/) and evaluate how the precision and recall of GeoDeepDive improves with the table information. 


10 References:
1. pdf2table (Yildiz et al.)
2. Table Extraction Using CRF (Pinto et al.)
3. Table Seer (Liu et al.)
4. Identifying table boundaries (Liu et al.)
5. http://cseweb.ucsd.edu/~elkan/250B/cikmtutorial.pdf


